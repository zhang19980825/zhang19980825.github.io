{"meta":{"title":"一辈子很长，要和有趣的人度过。","subtitle":null,"description":null,"author":"ZhangYang","url":"http://yoursite.com"},"pages":[],"posts":[{"title":"MySQL主从复制，读写分离，分库分表Mycat","slug":"MySQL主从复制，读写分离，分库分表Mycat","date":"2019-01-28T15:10:16.000Z","updated":"2019-01-29T15:25:36.063Z","comments":true,"path":"2019/01/28/MySQL主从复制，读写分离，分库分表Mycat/","link":"","permalink":"http://yoursite.com/2019/01/28/MySQL主从复制，读写分离，分库分表Mycat/","excerpt":"","text":"MySQL主从复制主从复制主要涉及三个线程：binlog 线程、I/O 线程和 SQL 线程。1.binlog 线程 ：负责将主服务器上的数据更改写入二进制日志中。2.I/O 线程 ：负责从主服务器上读取二进制日志，并写入从服务器的中继日志中。3.SQL 线程 ：负责读取中继日志并重放其中的 SQL 语句。首先关闭主从服务器的防火墙 主服务器的配置：1.修改my.conf文件：在[mysqld]段下添加： #启用二进制日志log-bin=mysql-bin #服务器唯一ID，一般取IP最后一段server-id=133 2.第二步：重启mysql服务service mysqld restart 3.第三步：建立帐户并授权slave（登录到MySQL）mysql&gt;GRANT FILE ON . TO ‘root‘@’%’ IDENTIFIED BY ‘123456’; mysql&gt;GRANT REPLICATION SLAVE, REPLICATION CLIENT ON . to ‘root‘@’%’ identified by ‘root’; mysql&gt;GRANT REPLICATION SLAVE ON . to ‘root‘@’%’ identified by ‘root’; #一般不用root帐号，“%”表示所有客户端都可能连，只要帐号，密码正确，此处可用具体客户端IP代替，如192.168.145.226，加强安全。 刷新权限mysql&gt; FLUSH PRIVILEGES;4.show master status; 查询master的状态 从服务器配置第一步：修改my.conf文件[mysqld]server-id=135第二步：删除UUID文件(如果是直接拷贝虚拟机的话，肯定会出现这个错误，如果重新装了的话可以越过此步骤)删除/var/lib/mysql/auto.cnf文件，重新启动服务。第三步：重启并登录到MySQL进行配置从服务器1mysql&gt;change master to master_host=&apos;192.168.10.133&apos;,master_port=3306,master_user=&apos;root&apos;,master_password=&apos;root&apos;,master_log_file=&apos;mysql-bin.000001&apos;,master_log_pos=569 第四步：启动从服务器复制功能mysql&gt;start slave;第五步：检查从服务器复制功能状态：mysql&gt; show slave status 集群搭建之读写分离主服务器处理写操作以及实时性要求比较高的读操作，而从服务器处理读操作。读写分离能提高性能的原因在于：1.主从服务器负责各自的读和写，极大程度缓解了锁的争用；2.从服务器可以使用 MyISAM，提升查询性能以及节约系统开销；增加冗余，提高可用性。3.读写分离常用代理方式来实现，代理服务器接收应用层传来的读写请求，然后决定转发到哪个服务器。 1. MySQL-Proxy安装 ( MySQL-Proxy)相当于是封装了MysqlServer准备一台机器作为MySQL Proxy上传压缩包解压缩tar -xf mysql-proxy-0.8.5-linux-el6-x86-64bit.tar.gz -C /kkb MySQL-Proxy配置1.创建mysql-proxy.cnf文件并进行相关配置2.修改mysql-proxy.cnf文件的权限3.修改rw-splitting.lua脚本（mysql-proxy/share/doc/mysql-proxy/rw-splitting.lua）4.MySQL-Proxy启动域测试./mysql-proxy –defaults-file=mysql-proxy.cnf配置文件的地址在其他客户端，通过mysql命令去连接MySQL Proxy机器 MySQL分库分表MyCAT使用Mysql的通讯协议模拟成了一个Mysql服务器，并建立了完整的Schema（数据库）、Table （数据表）、User(用户)的逻辑模型，并将这套逻辑模型映射到后端的存储节点DataNode（MySQL Instance）上的真实物理库中，这样一来，所有能使用Mysql的客户端以及编程语言都能将MyCAT当成是Mysql Server来使用，不必开发新的客户端协议。Mycat的安装就不介绍了，记住首先得安装jdkMyCAT支持水平分片与垂直分片：1.水平分片：一个表格的数据分割到多个节点上，按照行分隔。2.垂直分片：一个数据库中多个表格A，B，C，A存储到节点1上，B存储到节点2上，C存储到节点3上。 1、Schema：逻辑库，与MySQL中的Database（数据库）对应，一个逻辑库中定义了所包括的Table。2、Table：表，即物理数据库中存储的某一张表，与传统数据库不同，这里的表格需要声明其所存储的逻辑数据节点DataNode。在此可以指定表的分片规则。3、DataNode：MyCAT的逻辑数据节点，是存放table的具体物理节点，也称之为分片节点，通过DataSource来关联到后端某个具体数据库上4、DataSource：定义某个物理库的访问地址，用于捆绑到Datanode上 模拟需求：把商品表分片存储到三个数据节点上。1.在MySQL的配置文件中my.ini [mysqld] 中增加一行 lower_case_table_names = 1 设置为Mysql大小写不敏感2.Schema.xml配置1234567891011121314151617181920212223242526272829303132&lt;?xml version=&quot;1.0&quot;?&gt;&lt;!DOCTYPE mycat:schema SYSTEM &quot;schema.dtd&quot;&gt;&lt;mycat:schema xmlns:mycat=&quot;http://org.opencloudb/&quot;&gt; &lt;schema name=&quot;TESTDB&quot; checkSQLschema=&quot;false&quot; sqlMaxLimit=&quot;100&quot;&gt; &lt;!-- auto sharding by id (long) --&gt; &lt;table name=&quot;TB_ITEM&quot; dataNode=&quot;dn1,dn2,dn3&quot; rule=&quot;auto-sharding-long&quot; /&gt; &lt;table name=&quot;TB_USER&quot; primaryKey=&quot;ID&quot; type=&quot;global&quot; dataNode=&quot;dn1,dn2&quot; /&gt; &lt;/schema&gt; &lt;dataNode name=&quot;dn1&quot; dataHost=&quot;localhost1&quot; database=&quot;db1&quot; /&gt; &lt;dataNode name=&quot;dn2&quot; dataHost=&quot;localhost2&quot; database=&quot;db2&quot; /&gt; &lt;dataNode name=&quot;dn3&quot; dataHost=&quot;localhost1&quot; database=&quot;db3&quot; /&gt; &lt;dataHost name=&quot;localhost1&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;0&quot; writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;native&quot; switchType=&quot;1&quot; slaveThreshold=&quot;100&quot;&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;!-- can have multi write hosts --&gt; &lt;writeHost host=&quot;hostM1&quot; url=&quot;192.168.25.134:3306&quot; user=&quot;root&quot; password=&quot;root&quot;&gt; &lt;!-- can have multi read hosts --&gt; &lt;/writeHost&gt; &lt;/dataHost&gt; &lt;dataHost name=&quot;localhost2&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;0&quot; writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;native&quot; switchType=&quot;1&quot; slaveThreshold=&quot;100&quot;&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;!-- can have multi write hosts --&gt; &lt;writeHost host=&quot;hostM1&quot; url=&quot;192.168.25.166:3306&quot; user=&quot;root&quot; password=&quot;root&quot;&gt; &lt;!-- can have multi read hosts --&gt; &lt;/writeHost&gt; &lt;/dataHost&gt;&lt;/mycat:schema&gt; 3.配置server.xml12345&lt;user name=&quot;test&quot;&gt; &lt;property name=&quot;password&quot;&gt;test&lt;/property&gt; &lt;property name=&quot;schemas&quot;&gt;TESTDB&lt;/property&gt; &lt;property name=&quot;readOnly&quot;&gt;true&lt;/property&gt;&lt;/user&gt; 4.配置rule.xmlrule.xml里面就定义了我们对表进行拆分所涉及到的规则定义。我们可以灵活的对表使用不同的分片算法，或者对表使用相同的算法但具体的参数不同。这个文件里面主要有tableRule和function这两个标签。在具体使用过程中可以按照需求添加tableRule和function。 Mycat读写分离MyCat的读写分离是建立在MySQL主从复制基础之上实现的。只需要改变schema.xml的配置文件123456789101112&lt;dataNode name=&quot;dn1&quot; dataHost=&quot;localhost1&quot; database=&quot;db1&quot; /&gt; &lt;dataNode name=&quot;dn2&quot; dataHost=&quot;localhost1&quot; database=&quot;db2&quot; /&gt; &lt;dataNode name=&quot;dn3&quot; dataHost=&quot;localhost1&quot; database=&quot;db3&quot; /&gt; &lt;dataHost name=&quot;localhost1&quot; maxCon=&quot;1000&quot; minCon=&quot;10&quot; balance=&quot;1&quot; writeType=&quot;0&quot; dbType=&quot;mysql&quot; dbDriver=&quot;native&quot; switchType=&quot;2&quot; slaveThreshold=&quot;100&quot;&gt; &lt;heartbeat&gt;show slave status&lt;/heartbeat&gt; &lt;writeHost host=&quot;hostM&quot; url=&quot;192.168.25.134:3306&quot; user=&quot;root&quot; password=&quot;root&quot;&gt; &lt;readHost host=&quot;hostS&quot; url=&quot;192.168.25.166:3306&quot; user=&quot;root&quot; password=&quot;root&quot; /&gt; &lt;/writeHost&gt; &lt;/dataHost&gt; Balance参数设置：1.balance=“0”, 所有读操作都发送到当前可用的writeHost上。2.balance=“1”，所有读操作都随机的发送到readHost。3.balance=“2”，所有读操作都随机的在writeHost、readhost上分发WriteType参数设置：1.writeType=“0”, 所有写操作都发送到可用的writeHost上。2.writeType=“1”，所有写操作都随机的发送到readHost。3.writeType=“2”，所有写操作都随机的在writeHost、readhost分上发。switchType 目前有三种选择：-1：表示不自动切换1 ：默认值，自动切换2 ：基于MySQL主从同步的状态决定是否切换","categories":[],"tags":[]},{"title":"MySQL复习知识点","slug":"MySQL复习","date":"2019-01-27T02:41:05.000Z","updated":"2019-01-29T15:33:55.410Z","comments":true,"path":"2019/01/27/MySQL复习/","link":"","permalink":"http://yoursite.com/2019/01/27/MySQL复习/","excerpt":"","text":"MySQL事务事务指的是满足 ACID 特性的一组操作，可以通过 Commit 提交一个事务，也可以使用 Rollback 进行回滚。 1.原子性（Atomicity）事务被视为不可分割的最小单元，事务的所有操作要么全部提交成功，要么全部失败回滚。回滚可以用日志来实现，日志记录着事务所执行的修改操作，在回滚时反向执行这些修改操作即可。2.一致性（Consistency）数据库在事务执行前后都保持一致性状态。在一致性状态下，所有事务对一个数据的读取结果都是相同的。3.隔离性（Isolation）一个事务所做的修改在最终提交以前，对其它事务是不可见的。4.持久性（Durability）一旦事务提交，则其所做的修改将会永远保存到数据库中。即使系统发生崩溃，事务执行的结果也不能丢失。可以通过数据库备份和恢复来实现，在系统发生崩溃时，使用备份的数据库进行数据恢复。 事务的 ACID 特性概念简单，但不是很好理解，主要是因为这几个特性不是一种平级关系： 只有满足一致性，事务的执行结果才是正确的。 在无并发的情况下，事务串行执行，隔离性一定能够满足。此时只要能满足原子性，就一定能满足一致性。 在并发的情况下，多个事务并行执行，事务不仅要满足原子性，还需要满足隔离性，才能满足一致性。 事务满足持久化是为了能应对数据库崩溃的情况。 并发一致性问题在并发环境下，事务的隔离性很难保证，因此会出现很多并发一致性问题。1.丢失修改T1 和 T2 两个事务都对一个数据进行修改，T1 先修改，T2 随后修改T2 的修改覆盖了 T1 的修改。 2.读脏数据T1 修改一个数据，T2 随后读取这个数据。如果 T1 撤销了这次修改，那么 T2 读取的数据是脏数据。 3.不可重复读T2 读取一个数据，T1 对该数据做了修改。如果 T2 再次读取这个数据，此时读取的结果和第一次读取的结果不同。 4.幻影读T1 读取某个范围的数据，T2 在这个范围内插入新的数据，T1 再次读取这个范围的数据，此时读取的结果和和第一次读取的结果不同。 产生并发不一致性问题主要原因是破坏了事务的隔离性，解决方法是通过并发控制来保证隔离性。并发控制可以通过封锁来实现，但是封锁操作需要用户自己控制，相当复杂。数据库管理系统提供了事务的隔离级别，让用户以一种更轻松的方式处理并发一致性问题。 隔离级别未提交读（READ UNCOMMITTED）事务中的修改，即使没有提交，对其它事务也是可见的。 提交读（READ COMMITTED）一个事务只能读取已经提交的事务所做的修改。换句话说，一个事务所做的修改在提交之前对其它事务是不可见的。 可重复读（REPEATABLE READ）保证在同一个事务中多次读取同样数据的结果是一样的。 可串行化（SERIALIZABLE）强制事务串行执行。 Next-Key LocksNext-Key Locks 是 MySQL 的 InnoDB 存储引擎的一种锁实现。MVCC 不能解决幻读的问题，Next-Key Locks 就是为了解决这个问题而存在的。在可重复读（REPEATABLE READ）隔离级别下，使用 MVCC + Next-Key Locks 可以解决幻读问题。 Record Locks锁定一个记录上的索引，而不是记录本身。如果表没有设置索引，InnoDB 会自动在主键上创建隐藏的聚簇索引，因此 Record Locks 依然可以使用。 Gap Locks锁定索引之间的间隙，但是不包含索引本身。例如当一个事务执行以下语句，其它事务就不能在 t.c 中插入 15。SELECT c FROM t WHERE c BETWEEN 10 and 20 FOR UPDATE; 多版本并发控制多版本并发控制（Multi-Version Concurrency Control, MVCC）是 MySQL 的 InnoDB 存储引擎实现隔离级别的一种具体方式，用于实现提交读和可重复读这两种隔离级别。而未提交读隔离级别总是读取最新的数据行，无需使用 MVCC。可串行化隔离级别需要对所有读取的行都加锁，单纯使用 MVCC 无法实现。版本号 系统版本号：是一个递增的数字，每开始一个新的事务，系统版本号就会自动递增。 事务版本号：事务开始时的系统版本号。 隐藏的列MVCC 在每行记录后面都保存着两个隐藏的列，用来存储两个版本号： 创建版本号：指示创建一个数据行的快照时的系统版本号； 删除版本号：如果该快照的删除版本号大于当前事务版本号表示该快照有效，否则表示该快照已经被删除了。 Next-Key Locks它是 Record Locks 和 Gap Locks 的结合，不仅锁定一个记录上的索引，也锁定索引之间的间隙。例如一个索引包含以下值：10, 11, 13, and 20，那么就需要锁定以下区间：(negative infinity, 10](10, 11](11, 13](13, 20](20, positive infinity) MySQL索引索引的分类1.索引是在存储引擎中实现的，也就是说不同的存储引擎，会使用不同的索引 MyISAM和InnoDB存储引擎：只支持BTREE索引， 也就是说默认使用BTREE，不能够更换 MEMORY/HEAP存储引擎：支持HASH和BTREE索引 索引的分类 单列索引： 普通索引：MySQL中基本索引类型，没有什么限制，允许在定义索引的列中插入重复值和空值，纯粹为了查询数据更快一点。 唯一索引：索引列中的值必须是唯一的，但是允许为空值， 主键索引：是一种特殊的唯一索引，不允许有空值。 组合索引 在表中的多个字段组合上创建的索引，只有在查询条件中使用了这些字段的左边字段时，索引才会被使用，使用组合索引时遵循最左前缀集合。 全文索引 全文索引，只有在MyISAM引擎上才能使用，只能在CHAR,VARCHAR,TEXT类型字段上使用全文索引。 空间索引：不做介绍，一般使用不到。 索引的存储结构https://www.cs.usfca.edu/~galles/visualization/Algorithms.html--可以更好的理解数据结构及各种树的添加删除节点1.B+Tree 索引是大多数 MySQL 存储引擎的默认索引类型。因为不再需要进行全表扫描，只需要对树进行搜索即可，因此查找速度快很多。除了用于查找，还可以用于排序和分组。可以指定多个列作为索引列，多个索引列共同组成键。适用于全键值、键值范围和键前缀查找，其中键前缀查找只适用于最左前缀查找。如果不是按照索引列的顺序进行查找，则无法使用索引。InnoDB 的 B+Tree 索引分为主索引和辅助索引。主索引的叶子节点 data 域记录着完整的数据记录，这种索引方式被称为聚簇索引。因为无法把数据行存放在两个不同的地方，所以一个表只能有一个聚簇索引。辅助索引的叶子节点的 data 域记录着主键的值，因此在使用辅助索引进行查找时，需要先查找到主键值，然后再到主索引中进行查找2.哈希索引哈希索引能以 O(1) 时间进行查找，但是失去了有序性，它具有以下限制：无法用于排序与分组；只支持精确查找，无法用于部分查找和范围查找。InnoDB 存储引擎有一个特殊的功能叫“自适应哈希索引”，当某个索引值被使用的非常频繁时，会在 B+Tree 索引之上再创建一个哈希索引，这样就让 B+Tree 索引具有哈希索引的一些优点，比如快速的哈希查找。3.全文索引MyISAM 存储引擎支持全文索引，用于查找文本中的关键词，而不是直接比较是否相等。查找条件使用 MATCH AGAINST，而不是普通的 WHERE。全文索引一般使用倒排索引实现，它记录着关键词到其所在文档的映射。InnoDB 存储引擎在 MySQL 5.6.4 版本中也开始支持全文索引。4.空间数据索引MyISAM 存储引擎支持空间数据索引（R-Tree），可以用于地理数据存储。空间数据索引会从所有维度来索引数据，可以有效地使用任意维度来进行组合查询。必须使用 GIS 相关的函数来维护数据。 存储引擎InnoDB是 MySQL 默认的事务型存储引擎，只有在需要它不支持的特性时，才考虑使用其它存储引擎。实现了四个标准的隔离级别，默认级别是可重复读（REPEATABLE READ）。在可重复读隔离级别下，通过多版本并发控制（MVCC）+ 间隙锁（Next-Key Locking）防止幻影读。主索引是聚簇索引，在索引中保存了数据，从而避免直接读取磁盘，因此对查询性能有很大的提升。内部做了很多优化，包括从磁盘读取数据时采用的可预测性读、能够加快读操作并且自动创建的自适应哈希索引、能够加速插入操作的插入缓冲区等。支持真正的在线热备份。其它存储引擎不支持在线热备份，要获取一致性视图需要停止对所有表的写入，而在读写混合场景中，停止写入可能也意味着停止读取。 MyISAM设计简单，数据以紧密格式存储。对于只读数据，或者表比较小、可以容忍修复操作，则依然可以使用它。提供了大量的特性，包括压缩表、空间数据索引等。不支持事务。不支持行级锁，只能对整张表加锁，读取时会对需要读到的所有表加共享锁，写入时则对表加排它锁。但在表有读取操作的同时，也可以往表中插入新的记录，这被称为并发插入（CONCURRENT INSERT）。可以手工或者自动执行检查和修复操作，但是和事务恢复以及崩溃恢复不同，可能导致一些数据丢失，而且修复操作是非常慢的。如果指定了 DELAY_KEY_WRITE 选项，在每次修改执行完成时，不会立即将修改的索引数据写入磁盘，而是会写到内存中的键缓冲区，只有在清理键缓冲区或者关闭表的时候才会将对应的索引块写入磁盘。这种方式可以极大的提升写入性能，但是在数据库或者主机崩溃时会造成索引损坏，需要执行修复操作。比较 事务：InnoDB 是事务型的，可以使用 Commit 和 Rollback 语句。 并发：MyISAM 只支持表级锁，而 InnoDB 还支持行级锁。 外键：InnoDB 支持外键。 备份：InnoDB 支持在线热备份。 崩溃恢复：MyISAM 崩溃后发生损坏的概率比 InnoDB 高很多，而且恢复的速度也更慢。 其它特性：MyISAM 支持压缩表和空间数据索引。 Mysql内部结构1.Connection Pool: 连接池 管理缓冲用户连接，线程处理等需要缓存的需求。 负责监听对 MySQL Server 的各种请求，接收连接请求，转发所有连接请求到线程管理模块。每一个连接上 MySQL Server 的客户端请求都会被分配（或创建）一个连接线程为其单独服务。 而连接线程的主要工作就是负责 MySQL Server 与客户端的通信，接受客户端的命令请求，传递 Server 端的结果信息等。线程管理模块则负责管理维护这些连接线程。包括线程的创建，线程的 cache 等。SQL Interface: SQL接口接受用户的SQL命令，并且返回用户需要查询的结果。比如select from就是调用SQL Interface2.Parser: 解析器 SQL命令传递到解析器的时候会被解析器验证和解析。主要功能： a . 将SQL语句进行语义和语法的分析，分解成数据结构，然后按照不同的操作类型进行分类，然后做出针对性的转发到后续步骤，以后SQL语句的传递和处理就是基于这个结构的。 b. 如果在分解构成中遇到错误，那么就说明这个sql语句是不合理的 3.Optimizer: 查询优化器 SQL语句在查询之前会使用查询优化器对查询进行优化。 它使用的是“选取-投影-联接”策略进行查询。 用一个例子就可以理解： select uid,name from user where gender = 1; 这个select 查询先根据where 语句进行选取，而不是先将表全部查询出来以后再进行过滤 这个select查询先根据uid和name进行属性投影，而不是将属性全部取出以后再进行过滤 将这两个查询条件联接起来生成最终查询结果4.Cache和Buffer： 查询缓存他的主要功能是将客户端提交给MySQL的 select请求的返回结果集 cache 到内存中，与该 query 的一个 hash 值 做一个对应。该 Query 所取数据的基表发生任何数据的变化之后， MySQL 会自动使该 query 的Cache 失效。在读写比例非常高的应用系统中， Query Cache 对性能的提高是非常显著的。当然它对内存的消耗也是非常大的。 如果查询缓存有命中的查询结果，查询语句就可以直接去查询缓存中取数据。这个缓存机制是由一系列小缓存组成的。比如表缓存，记录缓存，key缓存，权限缓存等 5.存储引擎接口存储引擎接口模块可以说是 MySQL 数据库中最有特色的一点了。目前各种数据库产品中，基本上只有 MySQL 可以实现其底层数据存储引擎的插件式管理。这个模块实际上只是 一个抽象类，但正是因为它成功地将各种数据处理高度抽象化，才成就了今天 MySQL 可插拔存储引擎的特色。 从图还可以看出，MySQL区别于其他数据库的最重要的特点就是其插件式的表存储引擎。MySQL插件式的存储引擎架构提供了一系列标准的管理和服务支持，这些标准与存储引擎本身无关，可能是每个数据库系统本身都必需的，如SQL分析器和优化器等，而存储引擎是底层物理结构的实现，每个存储引擎开发者都可以按照自己的意愿来进行开发。存储引擎是基于表的，而不是数据库。 Mysql物理结构：MySQL是通过文件系统对数据进行存储和管理的。MySQL从物理结构上可以分为日志文件和数据文件。1.日志文件MySQL通过日志记录了数据库操作信息和错误信息。常用的日志文件包括错误日志、二进制日志、查询日志、慢查询日志和 InnoDB 引擎在线 Redo 日志、中继日志等。2.数据文件查看MySQL数据文件：SHOW VARIABLES LIKE ‘%datadir%’; .frm文件：主要存放与表相关的数据信息,主要包括表结构的定义信息 .ibd和.ibdata文件：用来存储InnoDB存储引擎的表数据和索引信息 .myd文件：主要用来存储使用MyISAM存储引擎的表数据信息。 .myi文件：主要用来存储使用MyISAM存储引擎的表数据文件中任何索引的数据树。 MySQL性能优化性能优化的思路1.首先需要使用慢查询功能，去获取所有查询时间比较长的SQL语句这个文件默认是关闭的，需要手动开启慢查询日志，通过这个日志我们可以从中知道一下信息：第一行,SQL查询执行的时间第二行,执行SQL查询的连接信息，用户和连接IP第三行,记录了一些我们比较有用的信息，如下解析 Query_time,这条SQL执行的时间,越长则越慢 Lock_time,在MySQL服务器阶段(不是在存储引擎阶段)等待表锁时间 Rows_sent,查询返回的行数 Rows_examined,查询检查的行数，越长就当然越费时间第四行,设置时间戳，没有实际意义，只是和第一行对应执行时间。第五行及后面所有行（第二个# Time:之前）,执行的sql语句记录信息，因为sql可能会很长。2.其次使用explain命令去查看有问题的SQL的执行计划expain出来的信息有10列，分别是id、select_type、table、type、possible_keys、key、key_len、ref、rows、Extra,下面对这些字段进行解释： id: SELECT 查询的标识符. 每个 SELECT 都会自动分配一个唯一的标识符. select_type: SELECT 查询的类型. table: 查询的是哪个表 partitions: 匹配的分区 type: join 类型 possible_keys: 此次查询中可能选用的索引 key: 此次查询中确切使用到的索引. ref: 哪个字段或常数与 key 一起被使用 rows: 显示此查询一共扫描了多少行. 这个是一个估计值. filtered: 表示此查询条件所过滤的数据的百分比 extra: 额外的信息3.最后可以使用show profile[s] 查看有问题的SQL的性能使用情况Query Profiler是MYSQL自带的一种query诊断分析工具，通过它可以分析出一条SQL语句的性能瓶颈在什么地方。 这个也是默认关闭的,打开的方式为：set profiling=1;Query Profiler可以定位出一条SQL语句执行的各种资源消耗情况，比如CPU，IO等，以及该SQL执行所耗费的时间等。 MySQL的锁行级锁定（row-level）行级锁定最大的特点就是锁定对象的颗粒度很小，也是目前各大数据库管理软件所实现的锁定颗粒度最小的。由于锁定颗粒度很小，所以发生锁定资源争用的概率也最小，能够给予应用程序尽可能大的并发处理能力而提高一些需要高并发应用系统的整体性能。虽然能够在并发处理能力上面有较大的优势，但是行级锁定也因此带来了不少弊端。由于锁定资源的颗粒度很小，所以每次获取锁和释放锁需要做的事情也更多，带来的消耗自然也就更大了。此外，行级锁定也最容易发生死锁。表级锁定（table-level）和行级锁定相反，表级别的锁定是MySQL各存储引擎中最大颗粒度的锁定机制。该锁定机制最大的特点是实现逻辑非常简单，带来的系统负面影响最小。所以获取锁和释放锁的速度很快。由于表级锁一次会将整个表锁定，所以可以很好的避免困扰我们的死锁问题。当然，锁定颗粒度大所带来最大的负面影响就是出现锁定资源争用的概率也会最高，致使并大度大打折扣。页级锁定（page-level）页级锁定是MySQL中比较独特的一种锁定级别，在其他数据库管理软件中也并不是太常见。页级锁定的特点是锁定颗粒度介于行级锁定与表级锁之间，所以获取锁定所需要的资源开销，以及所能提供的并发处理能力也同样是介于上面二者之间。另外，页级锁定和行级锁定一样，会发生死锁。MySQL这3种锁的特性可大致归纳如下： 表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低； 行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高； 页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。 表级锁MySQL的表级锁定有两种模式：表共享读锁（Table Read Lock）和表独占写锁（Table Write Lock）。表共享读锁：当前session可以查询该表的记录，当前session不能查询其他没有加锁的表,当前session不能插入或者更新当前锁定的表其他sessionk可以查询该表的记录，其他session可以查询或更新未锁定的表,其他session插入或者更新锁定表会一直等待获得锁。表独占写锁：当前session对当前表的查询，插入，更新可以成功，其他session对锁定表的查询被阻塞,需要等待该锁被释放 InnoDB引擎的锁机制共享锁（S）：允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁。排他锁（X)：允许获得排他锁的事务更新数据，阻止其他事务取得相同数据集的共享读锁和排他写锁。意向共享锁（IS）：事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的IS锁。意向排他锁（IX）：事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前必须先取得该表的IX锁。说明：1）共享锁和排他锁都是行锁，意向锁都是表锁，应用中我们只会使用到共享锁和排他锁，意向锁是mysql内部使用的，不需要用户干预。2）对于UPDATE、DELETE和INSERT语句，InnoDB会自动给涉及数据集加排他锁（X)；对于普通SELECT语句，InnoDB不会加任何锁，事务可以通过以下语句显示给记录集加共享锁或排他锁。共享锁（S）：SELECT FROM table_name WHERE … LOCK IN SHARE MODE。排他锁（X)：SELECT FROM table_name WHERE … FOR UPDATE。 InnoDB行锁是通过给索引上的索引项加锁来实现的，因此InnoDB这种行锁实现特点意味着：只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁！Innodb的锁定是通过在指向数据记录的第一个索引键之前和最后一个索引键之后的空域空间上标记锁定信息而实现的。Innodb的这种锁定实现方式被称为“NEXT-KEYlocking”（间隙锁），因为Query执行过程中通过过范围查找的华，他会锁定整个范围内所有的索引键值，即使这个键值并不存在。","categories":[],"tags":[{"name":"MySQL复习知识点","slug":"MySQL复习知识点","permalink":"http://yoursite.com/tags/MySQL复习知识点/"}]},{"title":"大数据（内存限制）+快排优化","slug":"大数据（内存限制）+快排优化","date":"2019-01-24T16:24:52.000Z","updated":"2019-01-27T15:29:49.911Z","comments":true,"path":"2019/01/25/大数据（内存限制）+快排优化/","link":"","permalink":"http://yoursite.com/2019/01/25/大数据（内存限制）+快排优化/","excerpt":"","text":"布隆过滤器问题描述：判断一个黑名单是否在100亿黑名单之中，可根据url进行判断，每个网页的URL最多占用64B要求：1.有一定的判断失误率 2.要求使用的额外空间不能超过30G思想：先构建一个长度为m的bit类型的数组，数组的每一个元素都代表了一个bit，再假设有k哥hash函数，每个hash函数之间相互独立，对于同一个输入对象，经过hash函数计算出来的值也是相互独立的，那么当这100亿个URL经过k个hash函数计算的值也是相互独立的，这时把计算出来的值与数组长度-1进行与运算，算出来的值在相应的位置涂黑，如果算出同样的值，就涂黑的颜色变深，这样一个布隆过滤器就构建完成了，当现在要判断一个url是否是黑名单中的一个的时候，就让这个URL经过k次hash运算再与数组长度减一进行与运算，会得出k个值，如果说这k个值对应的数组有一个是白色的，那么就肯定不存在，否则的话，就大概率存在，因为存在特殊情况，比如说数组的长度选的太小，算出来的与长度-1相与的值就会把数组全部覆盖，这样就会出现误判的情况。因此数组的长度，哈希函数的个数都得进行折中的选择，这个具体的数字需要一定的数学公式推导。 20亿个整数中找出出现次数最多的数（有内存限制）思想：将这20亿个整数通过哈希函数分为符合内存的N个文件，因为hash函数不可能把相同的数哈希到同一个文件之中，同时这个n又要保证最坏的情况内存不会查超过题目所给的要求，然后用哈希表分别算出这n个文件中每一个数出现的次数，最后再比较这n个文件中出现次数最最多的一个数，例如：32位的整数存储数字肯定不会溢出，哈希表的key和value都是4B，那么当哈希表的记录数为2亿个时，会占用1.6GB的空间，所以可以取n可以取12,13,14,15 40亿个非负整数找到一个没出现过的数 32位数的范围是4294967295一般思想：申请一个数组数组大小为4294967295，遍历这40亿多个数，是几就把数组对应下标对应的数组设为1，第二次遍历的时候，看那个位置没有被设为1这个数组对应的下标对应的数就没有出现过。进阶思想：可以把这个数组分成64个区间，举个例子内个区间大约是67108864，即数组的容量，在申请一个长度为64的数组，这个数组就用来记录这64个区间所存的数的数量，这样必定有一个数组的值少于4294967295，这个时候只需要关注这个区间的数就可以了，假如这个区间是第25区间，那么下次再进行遍历这40亿个数的时候只需要关注第25区间的数，其他数字省略，例如现在num落在第25区间了，这个时候把num-25*67108864的值设为1，遍历完成之后看一下数组的那个位置没有被设置为1，就是没有出现过的数 100亿个URL中重复的URL/搜索词汇的TopK问题思想：运用哈希分流的思想，要么把文件分到不同的机器上，要么把大文件分成多个小文件，具体情况根据题目要求而定，把大文件分流到不同的机器上之后，可以运用哈希函数统计各个文件中URL出现的次数，从而找出重复的URL，或者通过排序的方式，一般通过堆排序的方式。 40亿个非负整数中找到出现两次的数思想：申请一个80亿的bit类型的数组，遍历这40亿个无符号整数，假如遍历到的这个值为num，就把bitArray[num2]和bitArray[num2+1]的值设为01，等到第二次遍历到num的值的时候，就把bitArray[num2]和bitArray[num2+1]的值设置为10，等到第三次碰到num值的时候，就把bitArray[num2]和bitArray[num2+1]的值设置为11，最后再把这个数组进行遍历，bitArray[num2]和bitArray[num2+1]的值如果都为1的话这个数就出现了两次。 引申问题–40亿个数的中位数 （分区间法）一致性哈希的原理背景：一般来说，会用服务器集群来实现数据缓存的存储，具体来说就是，对当前数据进行存储的时候，先计算出这条数据的id，采用哈希函数算出一个hash值，假设一共有N台机器，那么就用当前数据的哈希值与（N-1）进行与操作，这样肯定在N个机器的范围之中，但是这样会带来一定的问题，就是当增加机器或者减少机器的时候，已经存储的数据要发生存储位置的变化，带来的成本比较高。一致性哈希算法：我们假设数据通过哈希函数算出来的哈希值在0~N的范围之中，我们就让这N个数手拉手形成一个环状，有多少台机器就把多少台机器也放入这个环中，当存储数据的时候，数据所对应的哈希值肯定会对应环中的某一个节点，那么他要放入那一个机器之中呢?可以把它放入顺时针寻找的最近的机器上,如果加上新的机器或者减少机器的数量，只需要改变部分数据的迁移，减少了成本,但是这样会出现如果机器分配不均匀的情况，就会让某些机器放入较多的数据，这种问题的解决方法是增加虚拟节点，每一个真正的机器节点各自增加一个虚拟节点使得机器的分配均匀性，这样当数据找到它所对应的虚拟节点的时候,就让它跳转存储到它所对应的真实的节点进行存储。 快排优化（1.基数值每次都取左中右之间数字数值排中间的数 2.当数组的长度小于等于13时候，就用插入排序）12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879public class Test &#123; //传统的快速排序由于基数选取的不确定性，如果基数选取的是数组的最大值或者最小值，那么此时快速排序的时间复杂度的相当于冒泡排序，所以取三//数优化的方法，每次都取出数组首，尾，中间，都取出三个数大小排中间//的数， //确保快速排序的意义 public static int GetMidIndex(int a[], int left, int right) &#123; int mid = left + ((right - left) &gt;&gt; 1); if (a[left] &gt; a[mid]) &#123; if (a[left] &lt; a[right]) return left; else &#123; if (a[right] &gt; a[mid]) return right; else return mid; &#125; &#125; else &#123; if (mid &gt; right) return mid; else &#123; if (left &lt; right) return left; else return right; &#125; &#125; &#125;//快排优化--小区间优化，当数组的长度很小一般来说是13或者小于13的时候，使用直接插入排序会比较有效率 public static void InsertSort(int a[], int left, int right) &#123; int end = 0; for (int i = 1; i &lt; right; i++) &#123; end = i - 1; int temp = a[i]; while (end &gt;= 0) &#123; if (a[end] &gt; temp) &#123; a[end + 1] = a[end]; --end; &#125; else break; &#125; a[end + 1] = temp; &#125; &#125; public static void quickSort(int array[],int left,int right)&#123; if(left&gt;right)&#123; return; &#125; if((right-left+1)&lt;=13)&#123; InsertSort(array,left,right); &#125; int t; int i=left;//左边的指针 int j=right;//右边的指针 int temp=array[GetMidIndex(array,left,right)]; while(i!=j)&#123; //让右边的指针开始跑，找到第一个小于基数的值 while(array[j]&gt;=temp&amp;&amp;i&lt;j)&#123; j--; &#125; //让左边的指针开始跑，找到第一个大于基数的值 while(array[i]&lt;=temp&amp;&amp;i&lt;j)&#123; i++; &#125; t=array[i]; array[i]=array[j]; array[j]=t; &#125; array[left]=array[i]; array[i]=temp; Test.quickSort(array,left,i-1); Test.quickSort(array,i+1,right); &#125; public static void main(String[] args) &#123; int array[]=&#123;3,2,5,8,4,7,6,9&#125;; Test.quickSort(array,0,7); for(int i=0;i&lt;array.length;i++)&#123; System.out.println(array[i]); &#125; &#125;&#125;","categories":[],"tags":[{"name":"大数据（内存限制）+快排优化","slug":"大数据（内存限制）-快排优化","permalink":"http://yoursite.com/tags/大数据（内存限制）-快排优化/"}]},{"title":"Redis学习（第三次）","slug":"Redis学习（第三次）","date":"2019-01-23T16:24:52.000Z","updated":"2019-01-24T15:40:17.642Z","comments":true,"path":"2019/01/24/Redis学习（第三次）/","link":"","permalink":"http://yoursite.com/2019/01/24/Redis学习（第三次）/","excerpt":"","text":"Redis的主从复制由于没有服务器所以可以搭建伪节点（拷贝redis的bin目录改变其端口号） 主redis中的数据有两个副本（replication）即从redis1和从redis2，即使一台redis服务器宕机其它两台redis服务也可以继续提供服务。 主redis中的数据和从redis上的数据保持实时同步，当主redis写入数据时通过主从复制机制会复制到两个从redis服务上。 只有一个主redis，可以有多个从redis。 主从复制不会阻塞master，在同步数据时，master 可以继续处理client 请求 一个redis可以即是主又是从配置：主redis不用配置，从redis配置：修改从服务器上的redis.conf文件–slaveof 192.168.101.3 6379 实现原理 Redis的主从同步，分为全量同步和增量同步。 只有从机第一次连接上主机是全量同步 断线重连有可能触发全量同步也有可能是增量同步（master判断runid是否一致） 除此之外的情况都是增量同步 全量同步Redis的全量同步过程主要分三个阶段： 同步快照阶段：Master创建并发送快照给Slave,Slave载入并解析快照。Master同时将此阶段所产生的新的写命令存储到缓冲区。 同步写缓冲阶段：Master向Slave同步存储在缓冲区的写操作命令。 同步增量阶段：Master向Slave同步写操作命令。 增量同步 Redis增量同步主要指Slave完成初始化后开始正常工作时，Master发生的写操作同步到Slave的过程。 通常情况下，Master每执行一个写命令就会向Slave发送相同的写命令，然后Slave接收并执行。 9Redis Sentinel哨兵机制 Sentinel(哨兵)进程是用于监控redis集群中Master主服务器工作的状态 在Master主服务器发生故障的时候，可以实现Master和Slave服务器的切换，保证系统的高可用哨兵进程的工作方式1.每个Sentinel（哨兵）进程以每秒钟一次的频率向整个集群中的Master主服务器，Slave从服务器以及其他Sentinel（哨兵）进程发送一个 PING 命令。2.如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值， 则这个实例会被 Sentinel（哨兵）进程标记为主观下线（SDOWN）。3.如果一个Master主服务器被标记为主观下线（SDOWN），则正在监视这个Master主服务器的所有 Sentinel（哨兵）进程要以每秒一次的频率确认Master主服务器的确进入了主观下线状态。4.当有足够数量的 Sentinel（哨兵）进程（大于等于配置文件指定的值）在指定的时间范围内确认Master主服务器进入了主观下线状态（SDOWN）， 则Master主服务器会被标记为客观下线（ODOWN）。5.在一般情况下， 每个 Sentinel（哨兵）进程会以每 10 秒一次的频率向集群中的所有Master主服务器、Slave从服务器发送 INFO 命令。6.当Master主服务器被 Sentinel（哨兵）进程标记为客观下线（ODOWN）时，Sentinel（哨兵）进程向下线的 Master主服务器的所有 Slave从服务器发送 INFO 命令的频率会从 10 秒一次改为每秒一次。7.若没有足够数量的 Sentinel（哨兵）进程同意 Master主服务器下线， Master主服务器的客观下线状态就会被移除。若 Master主服务器重新向 Sentinel（哨兵）进程发送 PING 命令返回有效回复，Master主服务器的主观下线状态就会被移除。实际操作1.修改从机的sentinel.conf 1#sentinel monitor &lt;master-name&gt; &lt;master ip&gt; &lt;master port&gt; &lt;quorum&gt; 2.通过redis-sentinel启动哨兵服务1./redis-sentinel sentinel.conf Redis Cluster集群原理：(1)所有的redis节点彼此互联(PING-PONG机制),内部使用二进制协议优化传输速度和带宽.(2)节点的fail是通过集群中超过半数的节点检测失效时才生效.(3)客户端与redis节点直连,不需要中间proxy层.客户端不需要连接集群所有节点,连接集群中任何一个可用节点即可(4)redis-cluster把所有的物理节点映射到[0-16383]slot上,cluster 负责维护Redis 集群中内置了 16384 个哈希槽，当需要在 Redis 集群中放置一个 key-value 时，redis 先对 key 使用 crc16 算法算出一个结果，然后把结果对 16384 求余数，这样每个 key 都会对应一个编号在 0-16383 之间的哈希槽，redis 会根据节点数量大致均等的将哈希槽映射到不同的节点 redis-cluster投票:容错(1)节点失效判断：集群中所有master参与投票,如果半数以上master节点与其中一个master节点通信超过(cluster-node-timeout),认为该master节点挂掉.(2)集群失效判断:什么时候整个集群不可用(cluster_state:fail)?如果集群任意master挂掉,且当前master没有slave，则集群进入fail状态。也可以理解成集群的[0-16383]slot映射不完全时进入fail状态。如果集群超过半数以上master挂掉，无论是否有slave，集群进入fail状态。 安装Ruby环境redis集群需要使用集群管理脚本redis-trib.rb，它的执行相应依赖ruby环境。具体可见菜鸟教程，Ruby我也不是很懂。。。 Redis9集群的安装Redis集群至少需要三主三从，由于搞不到这么多的服务器。所以只好用伪集群进行学习，还是拷贝redis 的bin目录并编辑redis.conf文件，修改其中的端口号启动：1./redis-trib.rb create --replicas 1 192.168.10.133:7001 192.168.10.133:7002 192.168.10.133:7003 192.168.10.133:7004 192.168.10.133:7005 192.168.10.133:7006 默认前面三个是主Redis，后面三个是前面三个对应的从Redis服务器命令客户端连接集群：./redis-cli –h 服务器ip地址 –p 端口号 –c Redis+LUA整合使用说实话，没具体用过LUA,只知道几条命令：redis中执行LUA脚本：1EVAL script numkeys key [key ...] arg [arg ...] lua脚本中调用redis命令(redis.call())1eval &quot;return redis.call(&apos;set&apos;,KEYS[1],&apos;bar&apos;)&quot; 1 foo Redis消息模式队列模式使用list类型的lpush和rpop实现消息队列 消息接收方如果不知道队列中是否有消息，会一直发送rpop命令，如果这样的话，会每一次都建立一次连接，这样显然不好。 可以使用brpop命令，它如果从队列中取不出来数据，会一直阻塞，在一定范围内没有取出则返回null 发布订阅模式：SUBSCRIBE channel [channel …]订阅给定的一个或多个频道的信息。PUBLISH channel message 将信息 message 发送到指定的频道 channel 。PSUBSCRIBE pattern [pattern …]订阅一个或多个符合给定模式的频道。 缓存穿透 缓存击穿 缓存雪崩缓存穿透1.什么叫缓存穿透？一般的缓存系统，都是按照key去缓存查询，如果不存在对应的value，就应该去后端系统查找（比如DB）。如果key对应的value是一定不存在的，并且对该key并发请求量很大，就会对后端系统造成很大的压力。这就叫做缓存穿透。2.如何解决？ 对查询结果为空的情况也进行缓存，缓存时间设置短一点，或者该key对应的数据insert了之后清理缓存。 对一定不存在的key进行过滤。可以把所有的可能存在的key放到一个大的Bitmap中，查询时通过该bitmap过滤。（布隆表达式） 缓存雪崩1.什么叫缓存雪崩？当缓存服务器重启或者大量缓存集中在某一个时间段失效，这样在失效的时候，也会给后端系统(比如DB)带来很大压力。2.如何解决？ 在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个key只允许一个线程查询数据和写缓存，其他线程等待。 不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀。 做二级缓存，A1为原始缓存，A2为拷贝缓存，A1失效时，可以访问A2，A1缓存失效时间设置为短期，A2设置为长期（此点为补充）缓存击穿1.什么叫缓存击穿？ 对于一些设置了过期时间的key，如果这些key可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑一个问题：缓存被“击穿”的问题，这个和缓存雪崩的区别在于这里针对某一key缓存，前者则是很多key。 缓存在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。2.如何解决使用redis的setnx互斥锁先进行判断，这样其他线程就处于等待状态，保证不会有大并发操作去操作数据库。 if(redis.sexnx()==1){ //查询数据库 //加入线程 } 缓存淘汰策略之LRU最大缓存 在 redis 中，允许用户设置最大使用内存大小maxmemory，默认为0，没有指定最大缓存，如果有新的数据添加，超过最大内存，则会使redis崩溃，所以一定要设置。 redis 内存数据集大小上升到一定大小的时候，就会实行数据淘汰策略。 淘汰策略redis淘汰策略配置：maxmemory-policy voltile-lru redis 提供 6种数据淘汰策略：1.voltile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰2.volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰3.volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰4.allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰5.allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰6.no-enviction（驱逐）：禁止驱逐数据 LRU实现最常见的实现是使用一个链表保存缓存数据 新数据插入到链表头部； 每当缓存命中（即缓存数据被访问），则将数据移到链表头部； 当链表满的时候，将链表尾部的数据丢弃。Java中可以使用LinkedList和LinkedHashMap来实现LRU","categories":[],"tags":[{"name":"Redis学习（第三次）","slug":"Redis学习（第三次）","permalink":"http://yoursite.com/tags/Redis学习（第三次）/"}]},{"title":"Redis学习（第二次）","slug":"Redis学习（第二次）","date":"2019-01-20T09:43:22.000Z","updated":"2019-01-24T15:37:14.505Z","comments":true,"path":"2019/01/20/Redis学习（第二次）/","link":"","permalink":"http://yoursite.com/2019/01/20/Redis学习（第二次）/","excerpt":"","text":"Redis实现分布式锁Jedis连接Ubuntu上的linux：1.在redis配置文件redis.conf中注释掉# bind 127.0.0.1,bind命令表示绑定的ip才能访问redis服务器 加上bind 自己linux服务器的ip地址2.redis配置文件redis.conf中protected-mode yes 是否开启保护模式，由yes该为no3.关闭linux 的防火墙注意事项：互斥性：在任意时刻，只能有一个。客户端能持有锁同一性：加锁和解锁必须是同一个客户端，客户端不能解别的客户端的锁可重入性：即使有一个客户端在持有锁的期间崩溃而没有主动解锁，也能保证后续其他客户端能加锁。举例：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495package com.java.redis;import redis.clients.jedis.Jedis;import redis.clients.jedis.JedisPool;import redis.clients.jedis.JedisPoolConfig;public class JedisTest &#123; private static int port = 6379; private static String host = &quot;192.168.96.143&quot;; private static JedisPool pool; static &#123; JedisPoolConfig config = new JedisPoolConfig(); config.setMinIdle(5); pool = new JedisPool(config, host, port); &#125; public static Jedis getJedis() &#123; return pool.getResource(); &#125; /** * 获取分布式锁 * * @param lockKey * @param requestId * @param timeout * @return */ public static boolean getLock(String lockKey, String requestId, int timeout) &#123; // 获取Jedis对象，负责和远程redis服务器进行连接 Jedis jedis = getJedis(); // 参数三：NX和XX // 参数sin：EX和PX String result = jedis.set(lockKey, requestId, &quot;NX&quot;, &quot;EX&quot;, timeout); if (result == &quot;OK&quot;) &#123; return true; &#125; return false; &#125; public static synchronized boolean getLock2(String lockKey, String requestId, int timeout) &#123; // 获取Jedis对象，负责和远程redis服务器进行连接 Jedis jedis = getJedis(); Long result = jedis.setnx(lockKey, requestId); if (result == 1) &#123; // 设置有效期 jedis.expire(lockKey, timeout); return true; &#125; return false; &#125; /*** * 释放分布式锁的代码 * @param lockKey * @param requestId */ public static void releaseLock(String lockKey, String requestId) &#123; // 获取Jedis对象，负责和远程redis服务器进行连接 Jedis jedis = getJedis(); if (requestId.equals(jedis.get(lockKey))) &#123; jedis.del(lockKey); &#125; &#125; public static void main(String[] args) &#123; poolConnect(); &#125; public static void singleConnect() &#123; // Jedis单实例连接 Jedis je = new Jedis(host, port); String result = je.get(&quot;zhang&quot;); System.out.println(result); je.close(); &#125; public static void poolConnect() &#123; JedisPoolConfig config = new JedisPoolConfig(); config.setMinIdle(5);//连接池的最大连接数 JedisPool pool = new JedisPool(config, host, port); Jedis je = pool.getResource(); String result = je.get(&quot;zhang&quot;); System.out.println(result); je.close(); pool.close(); &#125;&#125; Spring整合JedisPOOL：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd &quot;&gt; &lt;!-- 连接池配置 --&gt; &lt;bean id=&quot;jedisPoolConfig&quot; class=&quot;redis.clients.jedis.JedisPoolConfig&quot;&gt; &lt;!-- 最大连接数 --&gt; &lt;property name=&quot;maxTotal&quot; value=&quot;30&quot; /&gt; &lt;!-- 最大空闲连接数 --&gt; &lt;property name=&quot;maxIdle&quot; value=&quot;10&quot; /&gt; &lt;!-- 每次释放连接的最大数目 --&gt; &lt;property name=&quot;numTestsPerEvictionRun&quot; value=&quot;1024&quot; /&gt; &lt;!-- 释放连接的扫描间隔（毫秒） --&gt; &lt;property name=&quot;timeBetweenEvictionRunsMillis&quot; value=&quot;30000&quot; /&gt; &lt;!-- 连接最小空闲时间 --&gt; &lt;property name=&quot;minEvictableIdleTimeMillis&quot; value=&quot;1800000&quot; /&gt; &lt;!-- 连接空闲多久后释放, 当空闲时间&gt;该值 且 空闲连接&gt;最大空闲连接数 时直接释放 --&gt; &lt;property name=&quot;softMinEvictableIdleTimeMillis&quot; value=&quot;10000&quot; /&gt; &lt;!-- 获取连接时的最大等待毫秒数,小于零:阻塞不确定的时间,默认-1 --&gt; &lt;property name=&quot;maxWaitMillis&quot; value=&quot;1500&quot; /&gt; &lt;!-- 在获取连接的时候检查有效性, 默认false --&gt; &lt;property name=&quot;testOnBorrow&quot; value=&quot;false&quot; /&gt; &lt;!-- 在空闲时检查有效性, 默认false --&gt; &lt;property name=&quot;testWhileIdle&quot; value=&quot;true&quot; /&gt; &lt;!-- 连接耗尽时是否阻塞, false报异常,ture阻塞直到超时, 默认true --&gt; &lt;property name=&quot;blockWhenExhausted&quot; value=&quot;false&quot; /&gt; &lt;/bean&gt; &lt;!-- redis单机 通过连接池 --&gt; &lt;bean id=&quot;jedisPool&quot; class=&quot;redis.clients.jedis.JedisPool&quot; destroy-method=&quot;close&quot;&gt; &lt;constructor-arg name=&quot;poolConfig&quot; ref=&quot;jedisPoolConfig&quot; /&gt; &lt;constructor-arg name=&quot;host&quot; value=&quot;192.168.242.130&quot; /&gt; &lt;constructor-arg name=&quot;port&quot; value=&quot;6379&quot; /&gt; &lt;/bean&gt;&lt;/beans&gt; Test：12345678910111213141516171819@Test public void testJedisPool() &#123; JedisPool pool = (JedisPool) applicationContext.getBean(&quot;jedisPool&quot;); Jedis jedis = null; try &#123; jedis = pool.getResource(); jedis.set(&quot;name&quot;, &quot;lisi&quot;); String name = jedis.get(&quot;name&quot;); System.out.println(name); &#125; catch (Exception ex) &#123; ex.printStackTrace(); &#125; finally &#123; if (jedis != null) &#123; // 关闭连接 jedis.close(); &#125; &#125; &#125; Redis持久化方案RDB是Redis默认采用的持久化方式，RDB方式是通过快照（snapshotting）完成的，当符合一定条件时Redis会自动将内存中的数据进行快照并持久化到硬盘。Redis会在指定的情况下触发快照1.符合自定义配置的快照规则2.执行save或者bgsave命令3.执行flushall命令4.执行主从复制操作在redis.conf中设置自定义快照规则 RDB持久化条件格式：save save 900 1 ： 表示15分钟（900秒钟）内至少1个键被更改则进行快照。可以配置多个条件（每行配置一个条件），每个条件之间是“或”的关系。 配置dir指定rdb快照文件的位置 配置dbfilename指定rdb快照文件的名称 快照的实现原理： redis使用fork函数复制一份当前进程的副本(子进程) 父进程继续接收并处理客户端发来的命令，而子进程开始将内存中的数据写入硬盘中的临时文件。 当子进程写入完所有数据后会用该临时文件替换旧的RDB文件，至此，一次快照操作完成。 RDB优缺点 缺点：使用RDB方式实现持久化，一旦Redis异常退出，就会丢失最后一次快照以后更改的所有数据。这个时候我们就需要根据具体的应用场景，通过组合设置自动快照条件的方式来将可能发生的数据损失控制在能够接受范围。如果数据相对来说比较重要，希望将损失降到最小，则可以使用AOF方式进行持久化 优点： RDB可以最大化Redis的性能：父进程在保存RDB文件时唯一要做的就是fork出一个子进程，然后这个子进程就会处理接下来的所有保存工作，父进程无序执行任何磁盘I/O操作。同时这个也是一个缺点，如果数据集比较大的时候，fork可以能比较耗时，造成服务器在一段时间内停止处理客户端的请求； AOF方式:开启AOF持久化后每执行一条会更改Redis中的数据的命令，Redis就会将该命令写入硬盘中的AOF文件，这一过程显然会降低Redis的性能，但大部分情况下这个影响是能够接受的，另外使用较快的硬盘可以提高AOF的性能。 可以通过修改redis.conf配置文件中的appendonly参数开启 AOF文件的保存位置和RDB文件的位置相同，都是通过dir参数设置的。 默认的文件名是appendonly.aof，可以通过appendfilename参数修改： AOF重写原理:Redis 可以在 AOF 文件体积变得过大时，自动地在后台对 AOF 进行重写重写后的新 AOF 文件包含了恢复当前数据集所需的最小命令集合。整个重写操作是绝对安全的，因为 Redis 在创建新 AOF 文件的过程中，会继续将命令追加到现有的 AOF 文件里面，即使重写过程中发生停机，现有的 AOF 文件也不会丢失。 而一旦新 AOF 文件创建完毕，Redis 就会从旧 AOF 文件切换到新 AOF 文件，并开始对新 AOF 文件进行追加操作。AOF 文件有序地保存了对数据库执行的所有写入操作， 这些写入操作以 Redis 协议的格式保存， 因此 AOF 文件的内容非常容易被人读懂， 对文件进行分析（parse）也很轻松 Redis每次更改数据的时候， aof机制都会将命令记录到aof文件，但是实际上由于操作系统的缓存机制，数据并没有实时写入到硬盘，而是进入硬盘缓存。再通过硬盘缓存机制去刷新到保存到文件 如何选择RDB和AOF 一般来说,如果对数据的安全性要求非常高的话，应该同时使用两种持久化功能。 如果可以承受数分钟以内的数据丢失，那么可以只使用 RDB 持久化。 有很多用户都只使用 AOF 持久化， 但并不推荐这种方式： 因为定时生成 RDB 快照（snapshot）非常便于进行数据库备份， 并且 RDB 恢复数据集的速度也要比 AOF 恢复的速度要快 。 两种持久化策略可以同时使用，也可以使用其中一种。如果同时使用的话， 那么Redis重启时，会优先使用AOF文件来还原数据","categories":[],"tags":[{"name":"Redis学习（第二次）","slug":"Redis学习（第二次）","permalink":"http://yoursite.com/tags/Redis学习（第二次）/"}]},{"title":"Redis学习（第一次）","slug":"Redis学习（第一次）","date":"2019-01-19T15:25:25.000Z","updated":"2019-01-21T15:19:32.735Z","comments":true,"path":"2019/01/19/Redis学习（第一次）/","link":"","permalink":"http://yoursite.com/2019/01/19/Redis学习（第一次）/","excerpt":"","text":"Redis数据结构分析1.简单动态字符串（String）这里的String并不等同于我们c语言中的String字符串类型，它被称为简单类型字符串（SDS）,先来看一下其定义1234567891011121314/* * 保存字符串对象的结构 */ struct sdshdr &#123; // buf 中已占用空间的长度 int len; // buf 中剩余可用空间的长度 int free; // 数据空间 char buf[]; &#125;; SDS和C语言中String的区别：1.获取字符串长度时间复杂度传统的C 字符串 使用长度为N+1 的字符串数组来表示长度为N 的字符串，所以为了获取一个长度为C字符串的长度，必须遍历整个字符串。和C 字符串不同，SDS 的数据结构中，有专门用于保存字符串长度的变量，我们可以通过获取len 属性的值，直接知道字符串长度。2.杜绝缓冲区溢出当在内存中有两个紧挨的字符串时，当要改变第二个字符串的时候，但是又忘了为字符串重新分配空间时，就会出现缓冲区溢出的情况，但是Redis在修改字符串的时候，会提前对内存空间进行一个重新分配的过程，可以避免这种问题3.减少修改字符串时带来的内存重分配次数简单来说就是c字符串修改n次字符串一定会分配n次内存，而Redis修改n次字符串至多分配n次内存4.字符串存储内容C 字符串中的字符必须符合某种编码，并且除了字符串的末尾之外，字符串里面不能包含空字符，否则最先被程序读入的空字符将被误认为是字符串结尾，这些限制使得C字符串只能保存文本数据，而不能保存想图片，音频，视频，压缩文件这样的二进制数据。但是在Redis中，不是靠空字符来判断字符串的结束的，而是通过len这个属性。那么，即便是中间出现了空字符对于SDS来说，读取该字符仍然是可以的。 2.链表ListNode作为链表的节点，并且是双向链表12345typedef struct listNode&#123; struct listNode *prev; struct listNode * next; void * value; &#125; 通过直接操作list 来操作链表1234567891011121314typedef struct list&#123; //表头节点 listNode * head; //表尾节点 listNode * tail; //链表长度 unsigned long len; //节点值复制函数 void *(*dup) (void *ptr); //节点值释放函数 void (*free) (void *ptr); //节点值对比函数 int (*match)(void *ptr, void *key);&#125; 链表的特性 双端：链表节点带有prev 和next 指针，获取某个节点的前置节点和后置节点的时间复杂度都是O（N） 无环：表头节点的 prev 指针和表尾节点的next 都指向NULL，对立案表的访问时以NULL为截止 表头和表尾：因为链表带有head指针和tail 指针，程序获取链表头结点和尾节点的时间复杂度为O(1) 长度计数器：链表中存有记录链表长度的属性 len 多态：链表节点使用 void* 指针来保存节点值，并且可以通过list 结构的dup 、 free、 match三个属性为节点值设置类型特定函数。 字典哈希表： 1234567891011typedef struct dictht &#123; //哈希表数组 dictEntry **table; //哈希表大小 unsigned long size; //哈希表大小掩码，用于计算索引值 unsigned long sizemask; //该哈希表已有节点的数量 unsigned long used;&#125; 哈希表节点（ dictEntry ） 123456789101112 typeof struct dictEntry&#123; //键 void *key; //值 union&#123; void *val; uint64_tu64; int64_ts64; &#125; struct dictEntry *next;&#125; 字典： 1234567891011 typedef struct dict &#123; // 类型特定函数 dictType *type; // 私有数据 void *privedata; // 哈希表 dictht ht[2]; // rehash 索引 in trehashidx;&#125; 解决哈希冲突:随着对哈希表的不断操作，哈希表保存的键值对会逐渐的发生改变，为了让哈希表的负载因子维持在一个合理的范围之内，我们需要对哈希表的大小进行相应的扩展或者压缩，这时候，我们可以通过 rehash（重新散列）操作来完成。 在实际开发过程中，这个rehash 操作并不是一次性、集中式完成的，而是分多次、渐进式地完成的。渐进式rehash 的详细步骤： 1、为ht[1] 分配空间，让字典同时持有ht[0]和ht[1]两个哈希表 2、在几点钟维持一个索引计数器变量rehashidx，并将它的值设置为0，表示rehash 开始 3、在rehash 进行期间，每次对字典执行CRUD操作时，程序除了执行指定的操作以外，还会将ht[0]中的数据rehash 到ht[1]表中，并且将rehashidx加一 4、当ht[0]中所有数据转移到ht[1]中时，将rehashidx 设置成-1，表示rehash 结束 跳跃表跳跃表（skiplist）是一种有序数据结构，它通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的Redis 的跳跃表 主要由两部分组成：zskiplist（链表）和zskiplistNode （节点） 123456789101112131415 typedef struct zskiplistNode&#123; //层：level 数组可以包含多个元素，每个元素都包含一个指向其他节点的指针。 struct zskiplistLevel&#123; //前进指针 struct zskiplistNode *forward; //跨度 unsigned int span; &#125; level[]; //后退指针 struct zskiplistNode *backward; //跳跃表中的所有节点都按分值从小到大排序。 double score; //成员对象 成员对象指向一个字符串，这个字符串对象保存着一个SDS值 robj *obj;&#125; 123456789 typedef struct zskiplist &#123; //表头节点和表尾节点 structz skiplistNode *header,*tail; //表中节点数量 unsigned long length; //表中层数最大的节点的层数 int level;&#125;zskiplist; 跳跃表是有序集合的底层实现之一 主要有zskiplist 和zskiplistNode两个结构组成 每个跳跃表节点的层高都是1至32之间的随机数 在同一个跳跃表中，多个节点可以包含相同的分值，但每个节点的对象必须是唯一的 节点按照分值的大小从大到小排序，如果分值相同，则按成员对象大小排序整数集合（Intset）整数集合其实就是一个特殊的集合，里面存储的数据只能够是整数，并且数据量不能过大。123456789typedef struct intset&#123; //编码方式 uint32_t enconding; // 集合包含的元素数量 uint32_t length; //保存元素的数组 int8_t contents[];&#125; intset 在默认情况下会帮我们设定整数集合中的编码方式，但是当我们存入的整数不符合整数集合中的编码格式时，就需要使用到Redis 中的升级策略来解决Intset 中升级整数集合并添加新元素共分为三步进行：1、根据新元素的类型，扩展整数集合底层数组的空间大小，并为新元素分配空间2、将底层数组现有的所有元素都转换成新的编码格式，重新分配空间3、将新元素加入到底层数组中 压缩列表 压缩列表是列表键和哈希键的底层实现之一。当一个列表键只把汗少量列表项，并且每个列表项要么就是小整数，要么就是长度比较短的字符串，那么Redis 就会使用压缩列表来做列表键的底层实现。压缩列表（ziplist）是Redis为了节省内存而开发的，是由一系列特殊编码的连续内存块组成的顺序型数据结构，一个压缩列表可以包含任意多个节点（entry），每个节点可以保存一个字节数组或者一个整数值。 压缩列表的原理：压缩列表并不是对数据利用某种算法进行压缩，而是将数据照一定规则编码在一块连续的内存区域，目的是节省内存。通常作为列表键和哈希键的底层实现之一。 Redis五种数据类型的底层实现 Redis中的每个对象都是由 redisObject 结构来表示： 12345678910111213 typedef struct redisObject&#123; //类型 unsigned type:4; //编码 unsigned encoding:4; //指向底层数据结构的指针 void *ptr; //引用计数 int refcount; //记录最后一次被程序访问的时间 unsigned lru:22; &#125;robj 对象的 prt 指针指向对象底层的数据结构，而数据结构由 encoding 属性来决定。每种类型的对象都至少使用了两种不同的编码： 1.字符串对象字符串对象的编码可以是int，raw或者embstr。 1、int 编码：保存的是可以用 long 类型表示的整数值。 2、raw 编码：保存长度大于44字节的字符串（redis3.2版本之前是39字节，之后是44字节）。 3、embstr 编码：保存长度小于44字节的字符串（redis3.2版本之前是39字节，之后是44字节）。int编码是用来保存整数值，raw编码是用来保存长字符串，而embstr是用来保存短字符串。当 int 编码保存的值不再是整数，或大小超过了long的范围时，自动转化为raw。对于 embstr 编码，由于 Redis 没有对其编写任何的修改程序（embstr 是只读的），在对embstr对象进行修改时，都会先转化为raw再进行修改，因此，只要是修改embstr对象，修改后的对象一定是raw的，无论是否达到了44个字节。 2.列表对象列表对象的编码可以是 ziplist(压缩列表) 和 linkedlist(双端链表)。当同时满足下面两个条件时，使用ziplist（压缩列表）编码： 1、列表保存元素个数小于512个 2、每个元素长度小于64字节不能满足这两个条件的时候使用 linkedlist 编码。 3.哈希对象哈希对象的编码可以是 ziplist 或者 hashtable。当使用ziplist，也就是压缩列表作为底层实现时，新增的键值对是保存到压缩列表的表尾。当使用 hashtable 编码时， hashtable 编码的哈希表对象底层使用字典数据结构，哈希对象中的每个键值对都使用一个字典键值对。和上面列表对象使用 ziplist 编码一样，当同时满足下面两个条件时，使用ziplist（压缩列表）编码： 1、列表保存元素个数小于512个 2、每个元素长度小于64字节不能满足这两个条件的时候使用 hashtable 编码。 4.集合对象集合对象的编码可以是 intset 或者 hashtable。 intset 编码的集合对象使用整数集合作为底层实现，集合对象包含的所有元素都被保存在整数集合中。 hashtable 编码的集合对象使用字典作为底层实现，字典的每个键都是一个字符串对象，这里的每个字符串对象就是一个集合中的元素，而字典的值则全部设置为 null。这里可以类比Java集合中HashSet 集合的实现，HashSet 集合是由 HashMap 来实现的，集合中的元素就是 HashMap 的key，而 HashMap 的值都设为 null。当集合同时满足以下两个条件时，使用 intset 编码： 1、集合对象中所有元素都是整数 2、集合对象所有元素数量不超过512 不能满足这两个条件的就使用 hashtable 编码。第二个条件可以通过配置文件的 set-max-intset-entries 进行配置。 5.有序集合对象有序集合的编码可以是 ziplist 或者 skiplist。ziplist 编码的有序集合对象使用压缩列表作为底层实现，每个集合元素使用两个紧挨在一起的压缩列表节点来保存，第一个节点保存元素的成员，第二个节点保存元素的分值。并且压缩列表内的集合元素按分值从小到大的顺序进行排列，小的放置在靠近表头的位置，大的放置在靠近表尾的位置。skiplist 编码的有序集合对象使用 zet 结构作为底层实现，一个 zset 结构同时包含一个字典和一个跳跃表： 字典的键保存元素的值，字典的值则保存元素的分值；跳跃表节点的 object 属性保存元素的成员，跳跃表节点的 score 属性保存元素的分值。 这两种数据结构会通过指针来共享相同元素的成员和分值，所以不会产生重复成员和分值，造成内存的浪费。 说明：其实有序集合单独使用字典或跳跃表其中一种数据结构都可以实现，但是这里使用两种数据结构组合起来，原因是假如我们单独使用 字典，虽然能以 O(1) 的时间复杂度查找成员的分值，但是因为字典是以无序的方式来保存集合元素，所以每次进行范围操作的时候都要进行排序；假如我们单独使用跳跃表来实现，虽然能执行范围操作，但是查找操作有 O(1)的复杂度变为了O(logN)。因此Redis使用了两种数据结构来共同实现有序集合。 Redis事务管理Redis事务介绍 Redis的事务是通过MULTI，EXEC，DISCARD和WATCH这四个命令来完成的。 Redis的单个命令都是原子性的，所以这里确保事务性的对象是命令集合。 Redis将命令集合序列化并确保处于同一事务的命令集合连续且不被打断的执行 Redis不支持回滚操作 MULTI 用于标记事务块的开始。 Redis会将后续的命令逐个放入队列中，然后使用EXEC命令原子化地执行这个命令序列。EXEC 在一个事务中执行所有先前放入队列的命令，然后恢复正常的连接状态DISCARD 清除所有先前在一个事务中放入队列的命令，然后恢复正常的连接状态。WATCH 当某个事务需要按条件执行时，就要使用这个命令将给定的键设置为受监控的状态。 注意事项：使用该命令可以实现redis的乐观锁。（就是说watch命令监控了一个key，当这个可以发生变化的时候，事务就不执行）UNWATCH 清除所有先前为一个事务监控的键。 事务失败处理Redis语法错误 （编译器出错）当multi启动事务之后，假如说有三条命令，而第一条命令出错，第二条命令正确，那么执行exec命令的时候，就会因为先执行第一条命令出错，后面都不会执行Redis类型错误（可以理解成运行期错误）例如：set s1 444 lpush s1 2 3 4 这两条命令会出现类型不匹配的问题 但是s1所对应的值还是会变为444为什么redis不支持事务回滚？1、大多数事务失败是因为语法错误或者类型错误，这两种错误，在开发阶段都是可以预见的2、redis为了性能方面就忽略了事务回滚","categories":[],"tags":[{"name":"Redis学习（第一次）","slug":"Redis学习（第一次）","permalink":"http://yoursite.com/tags/Redis学习（第一次）/"}]},{"title":"SpringMVC学习（第三次）","slug":"SpringMVC学习（第三次）","date":"2019-01-16T16:06:47.000Z","updated":"2019-01-19T16:07:01.945Z","comments":true,"path":"2019/01/17/SpringMVC学习（第三次）/","link":"","permalink":"http://yoursite.com/2019/01/17/SpringMVC学习（第三次）/","excerpt":"","text":"RESTful支持想要理解RESTful，必须先要理解http，RESTful是一种软件架构风格、设计风格，而不是标准，只是提供了一组设计原则和约束条件。它主要用于客户端和服务器交互类的软件。基于这个风格设计的软件可以更简洁，更有层次，更易于实现缓存等机制。其核心价值在于如何设计出符合 REST 风格的网络接口。 什么是RESTful?REST 指的是一组架构约束条件和原则。满足这些约束条件和原则的应用程序或设计就是 RESTful。 RESTful 的特性： 资源（Resources）：网络上的一个实体，或者说是网络上的一个具体信息。它可以是一段文本、一张图片、一首歌曲、一种服务，总之就是一个具体的存在。可以用一个 URI（统一资源定位符）指向它，每种资源对应一个特定的 URI 。要获取这个资源，访问它的 URI 就可以，因此 URI 即为每一个资源的独一无二的识别符。 表现层（Representation）：把资源具体呈现出来的形式，叫做它的表现层 （Representation）。比如，文本可以用 txt 格式表现，也可以用 HTML 格式、XML 格式、JSON 格式表现，甚至可以采用二进制格式。 状态转化（State Transfer）：每发出一个请求，就代表了客户端和服务器的一次交互过程。HTTP协议，是一个无状态协议，即所有的状态都保存在服务器端。因此，如果客户端想要操作服务器， 必须通过某种手段，让服务器端发生“状态转化”（State Transfer）。而这种转化是建立在表现层之上的，所以就是 “ 表现层状态转化” 。具体说， 就是 HTTP 协议里面，四个表示操作方式的动词：GET 、POST 、PUT 、DELETE 。它们分别对应四种基本操作：GET 用来获取资源，POST 用来新建资源，PUT 用来更新资源，DELETE 用来删除资源。 RESTful 的示例：/account/1 HTTP GET ： 得到 id = 1 的 account/account/1 HTTP DELETE： 删除 id = 1 的 account/account/1 HTTP PUT： 更新 id = 1 的 account SpringMVC对RESTful的支持URL-PATTERN ：设置为/，方便拦截RESTful 请求。@PathVariable：可以解析出来URL中的模板变量（{id}） RESTful的CRUD:@RequestMapping：通过设置method属性的CRUD，可以将同一个URL映射到不同的HandlerMethod方法上@GetMapping、@PostMapping、@PutMapping、@DeleteMapping注解同@RequestMapping注解的method属性设置。 RESTful的资源表述 RESTful服务中一个重要的特性就是一种资源可以有多种表现形式，在SpringMVC中可以使用ContentNegotiatingManager这个内容协商管理器来实现这种方式。 内容协商的方式有三种： 扩展名,比如.json表示我要JSON格式数据、.xml表示我要XML格式数据 请求参数：默认是”format” 请求头设置Accept参数，比如设置Accept为application/json表示要JSON格式数据 不过现在RESTful响应的数据一般都是JSON格式，所以一般也不使用内容协商管理器，直接使用@ResponseBody注解将数据按照JSON格式返回 静态资源访问mvc:resources因为&lt; url-pattern &gt;/&lt; /url-pattern &gt;在Tomcat服务器是默认的servlet；通过查看Tomcat web.xml可得知，它除了能够处理静态资源还能够处理HTTP缓存请求，媒体（音频/视频）数据流和文件下载简历。所以如果我们的项目中配置了”/“，会覆盖掉tomcat中的default servlet。所以当springMVC的前端控制器配置为“/”时，需要在主配置文件中配置放行静态资源。123&lt;!-- 当DispatcherServlet配置为/来拦截请求的时候，需要配置静态资源的访问映射 --&gt;&lt;mvc:resources location=&quot;/js/&quot; mapping=&quot;/js/**&quot;/&gt;&lt;mvc:resources location=&quot;/css/&quot; mapping=&quot;/css/**&quot;/&gt; 拦截器 SpringMVC拦截器（Interceptor）实现对每一个请求处理前后进行相关的业务处理，类似与servlet中的Filter。 SpringMVC 中的Interceptor 拦截请求是通过HandlerInterceptor来实现的。 在SpringMVC中定义一个Interceptor非常简单，主要是实现Spring的HandlerInterceptor接口 定义拦截器123456789101112131415161718192021222324252627282930public class MyHandlerIntercepter1 implements HandlerInterceptor&#123; //Handler执行前调用 //应用场景：登录认证、身份授权 //返回值为true则是放行，为false是不放行 @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; return false; &#125; //进入Handler开始执行，并且在返回ModelAndView之前调用 //应用场景：对ModelAndView对象操作，可以把公共模型数据传到前台，可以统一指定视图 @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; &#125; //执行完Handler之后调用 //应用场景：统一异常处理、统一日志处理 @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; &#125;&#125; 配置拦截器12345678910111213&lt;!-- 配置全局mapping的拦截器 --&gt;&lt;mvc:interceptors&gt; &lt;!-- 公共拦截器可以拦截所有请求，而且可以有多个 --&gt; &lt;bean class=&quot;com.kkb.ssm.interceptor.MyHandlerInterceptor1&quot; /&gt; &lt;bean class=&quot;com.kkb.ssm.interceptor.MyHandlerInterceptor2&quot; /&gt; &lt;!-- 如果有多个拦截器，则按照顺序进行配置 --&gt; &lt;mvc:interceptor&gt; &lt;!-- /**表示所有URL和子URL路径 --&gt; &lt;mvc:mapping path=&quot;/test/**&quot; /&gt; &lt;!-- 特定请求的拦截器只能有一个 --&gt; &lt;bean class=&quot;com.kkb.ssm.interceptor.MyHandlerInterceptor3&quot; /&gt; &lt;/mvc:interceptor&gt;&lt;/mvc:interceptors&gt; 实现登录验证的过程：拦截器对访问的请求URL进行拦截校验1、如果请求的URL是公开地址（无需登录就可以访问的URL,具体指的就是保护login字段的请求URL），采取放行。2、如果用户session存在，则放行。3、如果用户session中不存在，则跳转到登录页面。Controller类12345678910111213141516171819202122232425262728293031@Controllerpublic class LoginController &#123; //显示登录页面 @RequestMapping(&quot;/loginPage&quot;) public String loginPage()&#123; return &quot;login&quot;; &#125; // 登录 @RequestMapping(&quot;/login&quot;) public String login(HttpSession session, String username, String password) &#123; // Service进行用户身份验证 // 把用户信息保存到session中 session.setAttribute(&quot;username&quot;, username); // 重定向到商品列表页面 return &quot;redirect:/item/queryItem&quot;; &#125; // 退出 @RequestMapping(&quot;/logout&quot;) public String logout(HttpSession session) &#123; //清空session session.invalidate(); // 重定向到登录页面 return &quot;redirect:/loginPage&quot;; &#125;&#125; HandlerInterceptor类:12345678910111213141516171819202122232425262728293031323334353637public class LoginInterceptor implements HandlerInterceptor &#123; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; //获取请求的URI String requestURI = request.getRequestURI(); System.out.println(requestURI); // 1、 如果请求的URL是公开地址（无需登录就可以访问的URL），采取放行。 if(requestURI.indexOf(&quot;login&quot;)&gt;-1) return true;// 2、 如果用户session存在，则放行。 String username = (String) request.getSession().getAttribute(&quot;username&quot;); if(username !=null &amp;&amp; !username.equals(&quot;&quot;)) return true;// 3、 如果用户session中不存在，则跳转到登录页面。 response.sendRedirect(&quot;/ssm/loginPage&quot;); return false; &#125; @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; // TODO Auto-generated method stub &#125; @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; // TODO Auto-generated method stub &#125;&#125; HandlerInterceptor配置:123456789101112131415&lt;!-- 配置全局mapping的拦截器 --&gt;&lt;mvc:interceptors&gt; &lt;!-- 如果有多个拦截器，则按照顺序进行配置 --&gt; &lt;mvc:interceptor&gt; &lt;!-- /**表示所有URL和子URL路径 --&gt; &lt;mvc:mapping path=&quot;/**&quot; /&gt; &lt;bean class=&quot;com.kkb.ssm.interceptor.LoginInterceptor&quot; /&gt; &lt;/mvc:interceptor&gt; &lt;!-- 如果有多个拦截器，则按照顺序进行配置 --&gt; &lt;mvc:interceptor&gt; &lt;!-- /**表示所有URL和子URL路径 --&gt; &lt;mvc:mapping path=&quot;/**&quot; /&gt; &lt;bean class=&quot; com.kkb.ssm.interceptor.MyHandlerInterceptor&quot; /&gt; &lt;/mvc:interceptor&gt;&lt;/mvc:interceptors&gt; 在这里简单对比一下过滤器和拦截器的区别： 功能相同：拦截器和 Filter都能实现相应的功能，谁也不比谁强。 容器不同：拦截器构建在 Spring MVC 体系中；Filter 构建在 Servlet 容器之上。 使用便利性不同：拦截器提供了三个方法，分别在不同的时机执行；过滤器仅提供一个方法，当然也能实现拦截器的执行时机的效果，就是麻烦一些。跨域处理由于浏览器对于Javascript的同源策略的限制，导致A网站不能通过JS（主要就是Ajax请求）去访问B网站的数据，于是跨域问题就出现了。跨域指的是域名、端口、协议的组合不同就是跨域。解决跨域的方式有多种，比如基于JavaScript的解决方式、基于Jquery的JSONP方式、以及基于CORS的方式。JSONP和CORS的区别之一：JSONP只能解决get方式提交、CORS不仅支持GET方式，同时也支持POST提交方式。 CORS原理：只需要向响应头header中注入Access-Control-Allow-Origin，这样浏览器检测到header中的Access-Control-Allow-Origin，则就可以跨域操作了。 简单请求：对于简单请求，浏览器直接发出CORS请求。具体来说，就是在头信息之中，增加一个Origin字段。非简单请求：非简单请求是那种对服务器有特殊要求的请求，比如请求方法是PUT或DELETE，或者Content-Type字段的类型是application/json。非简单请求的CORS请求，会在正式通信之前，增加一次HTTP查询请求，称为”预检”请求（preflight）。浏览器先询问服务器，当前网页所在的域名是否在服务器的许可名单之中，以及可以使用哪些HTTP动词和头信息字段。只有得到肯定答复，浏览器才会发出正式的XMLHttpRequest请求，否则就报错。 CORS实现是使用springmvc的拦截器实现的跨域不提交Cookie1234567891011121314151617public class AllowOriginInterceptor implements HandlerInterceptor &#123; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object arg2) throws Exception &#123; // 有跨域行为时参考网址 http://namezhou.iteye.com/blog/2384434 if (request.getHeader(&quot;Origin&quot;) != null) &#123; response.setContentType(&quot;text/html;charset=UTF-8&quot;); // 允许哪一个URL response.setHeader(&quot;Access-Control-Allow-Origin&quot;, &quot;*&quot;); // 允许那种请求方法 response.setHeader(&quot;Access-Control-Allow-Methods&quot;, &quot;POST, GET, OPTIONS, DELETE&quot;); response.setHeader(&quot;XDomainRequestAllowed&quot;, &quot;1&quot;); System.out.println(&quot;正在跨域&quot;); &#125; return true; &#125; &#125; 再加上拦截器的配置如果有多个拦截器，一定要把处理跨域请求的拦截器放到首位。 跨域提交Cookie1234567891011121314151617181920212223public class AllowOriginInterceptor implements HandlerInterceptor &#123; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object arg2) throws Exception &#123; // 有跨域行为时参考网址 http://namezhou.iteye.com/blog/2384434 if (request.getHeader(&quot;Origin&quot;) != null) &#123; response.setContentType(&quot;text/html;charset=UTF-8&quot;); // 允许哪一个URL 访问 request.getHeader(&quot;Origin&quot;) 根据请求来的url动态允许 response.setHeader(&quot;Access-Control-Allow-Origin&quot;, request.getHeader(&quot;Origin&quot;)); // 允许那种请求方法 response.setHeader(&quot;Access-Control-Allow-Methods&quot;, &quot;POST, GET, OPTIONS, DELETE,HEAD&quot;); response.setHeader(&quot;Access-Control-Max-Age&quot;, &quot;0&quot;); // 允许请求头里的参数列表 response.setHeader(&quot;Access-Control-Allow-Headers&quot;, &quot;Origin, No-Cache, X-Requested-With, If-Modified-Since, Pragma, Last-Modified, Cache-Control, Expires, Content-Type, X-E4M-With,userId,token&quot;); // 允许对方带cookie访问 response.setHeader(&quot;Access-Control-Allow-Credentials&quot;, &quot;true&quot;); response.setHeader(&quot;XDomainRequestAllowed&quot;, &quot;1&quot;); System.out.println(&quot;正在跨域&quot;); &#125; return true; &#125;&#125;","categories":[],"tags":[{"name":"SpringMVC学习（第三次）","slug":"SpringMVC学习（第三次）","permalink":"http://yoursite.com/tags/SpringMVC学习（第三次）/"}]},{"title":"SpringMVC学习（第二次）","slug":"SpringMVC学习（第二次）","date":"2019-01-13T15:41:12.000Z","updated":"2019-01-16T16:45:00.316Z","comments":true,"path":"2019/01/13/SpringMVC学习（第二次）/","link":"","permalink":"http://yoursite.com/2019/01/13/SpringMVC学习（第二次）/","excerpt":"","text":"设计模式—装饰模式意图：动态地给一个对象添加一些额外的职责。就增加功能来说，装饰器模式相比生成子类更为灵活。主要解决：一般的，我们为了扩展一个类经常使用继承方式实现，由于继承为类引入静态特征，并且随着扩展功能的增多，子类会很膨胀。何时使用：在不想增加很多子类的情况下扩展类。如何解决：将具体功能职责划分，同时继承装饰者模式。优点：装饰类和被装饰类可以独立发展，不会相互耦合，装饰模式是继承的一个替代模式，装饰模式可以动态扩展一个实现类的功能。缺点：多层装饰比较复杂。123456789101112/** * 被装饰类 * @author think * */public class Iphone6 implements Iphone &#123; @Override public void call() &#123; System.out.println(&quot;使用iphone6打电话，性能刚刚滴&quot;); &#125;&#125; 1234567891011121314151617181920212223/** * 装饰类（增强功能） * @author think * */public class IphoneDecorate implements Iphone&#123; //被装饰的目标类 private Iphone iphone; //通过构造参数将被装饰的类，传入过来 public IphoneDecorate(Iphone iphone) &#123; super(); this.iphone = iphone; &#125; @Override public void call() &#123; System.out.println(&quot;人猿泰山music。。。。。。&quot;); iphone.call(); &#125; &#125; 1234567891011121314151617181920212223/** * 装饰类（增强功能） * @author think * */public class IphoneDecorate implements Iphone&#123; //被装饰的目标类 private Iphone iphone; //通过构造参数将被装饰的类，传入过来 public IphoneDecorate(Iphone iphone) &#123; super(); this.iphone = iphone; &#125; @Override public void call() &#123; System.out.println(&quot;对对象的增强工作&quot;); iphone.call(); &#125; &#125; 设计模式—适配器模式意图：将一个类的接口转换成客户希望的另外一个接口。适配器模式使得原本由于接口不兼容而不能一起工作的那些类可以一起工作。主要解决：主要解决在软件系统中，常常要将一些”现存的对象”放到新的环境中，而新环境要求的接口是现对象不能满足的。何时使用： 1、系统需要使用现有的类，而此类的接口不符合系统的需要。 2、想要建立一个可以重复使用的类，用于与一些彼此之间没有太大关联的一些类，包括一些可能在将来引进的类一起工作，这些源类不一定有一致的接口。 3、通过接口转换，将一个类插入另一个类系中。（比如老虎和飞禽，现在多了一个飞虎，在不增加实体的需求下，增加一个适配器，在里面包容一个虎对象，实现飞的接口。）如何解决：继承或依赖（推荐）。优点： 1、可以让任何两个没有关联的类一起运行。 2、提高了类的复用。 3、增加了类的透明度。 4、灵活性好。缺点： 1、过多地使用适配器，会让系统非常零乱，不易整体进行把握。比如，明明看到调用的是 A 接口，其实内部被适配成了 B 接口的实现，一个系统如果太多出现这种情况，无异于一场灾难。因此如果不是很有必要，可以不使用适配器，而是直接对系统进行重构。 2.由于 JAVA 至多继承一个类，所以至多只能适配一个适配者类，而且目标类必须是抽象类。123456789/** * 德国标准的插排 * @author think * */public interface DBSocket &#123; void charge();&#125; 12345678910111213/** * 德国插排 * @author think * */public class DBSocketImpl implements DBSocket &#123; @Override public void charge() &#123; System.out.println(&quot;使用两眼插孔充电&quot;); &#125;&#125; 12345678/** * 中国插排 * @author think * */public interface GBSocket &#123; void charge();&#125; 12345678public class GBSocketImpl implements GBSocket &#123; @Override public void charge() &#123; System.out.println(&quot;使用三眼插孔充电&quot;); &#125;&#125; 1234567891011package com.kkb.ssm.design_pattern.adapter;/** * 这是国际标准 * @author think * */public interface GJBZSocket &#123; void charge();&#125; 123456789101112131415161718192021222324/*** * 适配器(将不同类型的GBSocket和DBSocket都适配成GJBZSocket) * * @author think * */public class SockerAdapter implements GJBZSocket &#123; private Object socket; public SockerAdapter(Object socket) &#123; super(); this.socket = socket; &#125; @Override public void charge() &#123; if (socket instanceof GBSocket) &#123; ((GBSocket)socket).charge(); &#125;else if (socket instanceof DBSocket) &#123; ((DBSocket)socket).charge(); &#125; &#125;&#125; 异常处理器一般来说当代码出现异常之后，类似404之类的页面肯定不能出现在页面上，这个时候就需要定义一个全局的自定义异常处理器，大部分公司应该都有自己的自定义异常处理类，应该都是封装好的代码，这里只是进行了解学习使用1.自定义异常类123456789101112131415161718192021222324/*** * 自定义编译时异常 * @author think * */public class CustomExcetion extends Exception &#123; private String msg; public CustomExcetion(String msg) &#123; super(); this.msg = msg; &#125; public String getMsg() &#123; return msg; &#125; public void setMsg(String msg) &#123; this.msg = msg; &#125; &#125; 2.自定义异常处理器1234567891011121314151617181920212223public class CustomExceptionResolver implements HandlerExceptionResolver &#123; @Override public ModelAndView resolveException(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) &#123; String message = &quot;&quot;; //异常处理逻辑 if (ex instanceof CustomExcetion) &#123; message = ((CustomExcetion)ex).getMsg(); &#125;else &#123; message = &quot;未知错误&quot;; &#125; ModelAndView mv = new ModelAndView(); mv.setViewName(&quot;error&quot;); mv.addObject(&quot;message&quot;, message); return mv; &#125;//在jsp页面接受这个穿过来的message就可以了&#125; 3.SpringMVC的异常处理器的配置12&lt;!-- 配置异常处理器 --&gt; &lt;bean class=&quot;com.kkb.ssm.exception.resolver.CustomExceptionResolver&quot;&gt;&lt;/bean&gt; 图片的上传SpringMVC文件上传的实现，是由commons-fileupload这个jar包实现的。在表现层需要MultipartFile 这个类，由于这个类是mvc的一个接口实现类，所以图片的上传一般都在表现层，不在服务层。具体原因可能是因为减少服务层对表现层的依赖1.文件上传需要指定enctype=”multipart/form-data”（jsp页面）2.配置Multipart解析器12345&lt;!-- 配置多部件解析器 --&gt; &lt;bean id=&quot;multipartResolver&quot; class=&quot;org.springframework.web.multipart.commons.CommonsMultipartResolver&quot;&gt; &lt;!-- 限制上传文件的大小 单位是byte--&gt; &lt;property name=&quot;maxUploadSize&quot; value=&quot;5000000&quot;&gt;&lt;/property&gt; &lt;/bean&gt; 3.Controller代码123456789101112131415161718192021222324252627282930@RequestMapping(&quot;updateItem&quot;)@ResponseBodypublic Item updateItem(Integer id, String name, Float price, Item item, MultipartFile pictureFile) throws Exception&#123; if (pictureFile != null) &#123; //获取上传文件名称 String originalFilename = pictureFile.getOriginalFilename(); if (originalFilename != null &amp;&amp; !&quot;&quot;.contentEquals(originalFilename)) &#123; //获取扩展名 String extName = originalFilename.substring(originalFilename.lastIndexOf(&quot;.&quot;)); //重新生成一个文件名称 String newFileName = UUID.randomUUID().toString()+extName; //指定存储文件的根目录 String baseDir=&quot;E:\\\\07-upload\\\\temp\\\\&quot;; File dirFile=new File(baseDir); if (!dirFile.exists()) &#123; dirFile.mkdirs(); &#125; //将上传的文件复制到新的文件(完整路径)中 pictureFile.transferTo(new File(baseDir + newFileName)); //保存文件路径 item.setPic(newFileName); &#125; &#125; //商品修改 service.updateItem(item); return item;&#125; 3.jsp页面123456&lt;tr&gt; &lt;td&gt;商品图片&lt;/td&gt; &lt;td&gt;&lt;c:if test=&quot;$&#123;item.pic !=null&#125;&quot;&gt; &lt;img src=&quot;http://localhost/pic/$&#123;item.pic&#125;&quot; width=100 height=100 /&gt;&lt;br /&gt; &lt;/c:if&gt; &lt;input type=&quot;file&quot; name=&quot;pictureFile&quot; /&gt;&lt;/td&gt;&lt;/tr&gt; Mock测试MockMVC是基于RESTful（下篇文章写）风格的SpringMVC的测试，我们可以测试完整的Spring MVC流程，即从URL请求到控制器处理，再到视图渲染都可以测试MockMVCBuilder * MockMvcBuilder是用来构造MockMvc的构造器 *其主要有两个实现：StandaloneMockMvcBuilder和DefaultMockMvcBuilder，分别对应之前的两种测试方式。 * 对于我们来说直接使用静态工厂MockMvcBuilders创建即可 MockMVCBuilders * 负责创建MockMVCBuilder对象 * 有两种创建方式 * standaloneSetup(Object... controllers): * 通过参数指定一组控制器，这样就不需要从上下文获取了。 * webAppContextSetup(WebApplicationContext wac) * 指定WebApplicationContext，将会从该上下文获取相应的控制器并得到相应的MockMvc MockMvc * 对于服务器端的Spring MVC测试支持主入口点。 * 通过MockMVCBuilder构造 * MockMVCBuilder由MockMVCBuilders建造者的静态方法去建造。 * 核心方法：perform(RequestBuilder rb)--- 执行一个RequestBuilder请求，会自动执行SpringMVC的流程并映射到相应的控制器执行处理，该方法的返回值是一ResultActions； ResultActions * andExpect：添加ResultMatcher验证规则，验证控制器执行完成后结果是否正确； * andDo：添加ResultHandler结果处理器，比如调试时打印结果到控制台； * andReturn：最后返回相应的MvcResult；然后进行自定义验证/进行下一步的异步处理； MockMvcRequestBuilders * 用来构建请求的 *其主要有两个子类MockHttpServletRequestBuilder和MockMultipartHttpServletRequestBuilder（如文件上传使用），即用来Mock客户端请求需要的所有数据。 MockMvcResultMatchers * 用来匹配执行完请求后的结果验证 * 如果匹配失败将抛出相应的异常 * 包含了很多验证API方法 MockMvcResultHandlers * 结果处理器，表示要对结果做点什么事情 * 比如此处使用MockMvcResultHandlers.print()输出整个响应结果信息。 MvcResult * 单元测试执行结果，可以针对执行结果进行自定义验证逻辑。 测试代码举例:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950//@WebAppConfiguration：可以在单元测试的时候，不用启动Servlet容器，就可以获取一个Web应用上下文@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = &quot;classpath:spring/*.xml&quot;)@WebAppConfigurationpublic class TestMockMVC &#123; @Autowired private WebApplicationContext wac; private MockMvc mockMvc; @Before public void setup() &#123; // 初始化一个MockMVC对象的方式有两种：单独设置、web应用上下文设置 // 建议使用Web应用上下文设置 mockMvc = MockMvcBuilders.webAppContextSetup(wac).build(); &#125; @Test public void test() throws Exception &#123; // 通过perform去发送一个HTTP请求 // andExpect：通过该方法，判断请求执行是否成功 // andDo :对请求之后的结果进行输出 MvcResult result = mockMvc.perform(MockMvcRequestBuilders.get(&quot;/item/showEdit&quot;).param(&quot;id&quot;, &quot;1&quot;)) .andExpect(MockMvcResultMatchers.view().name(&quot;item/item-edit&quot;)) .andExpect(MockMvcResultMatchers.status().isOk()) .andDo(MockMvcResultHandlers.print()) .andReturn(); System.out.println(&quot;================================&quot;); System.out.println(result.getHandler()); &#125; @Test public void test2() throws Exception &#123; // 通过perform去发送一个HTTP请求 // andExpect：通过该方法，判断请求执行是否成功 // andDo :对请求之后的结果进行输出 MvcResult result = mockMvc.perform(MockMvcRequestBuilders.get(&quot;/item/findItem&quot;).param(&quot;id&quot;, &quot;1&quot;)) .andExpect(MockMvcResultMatchers.status().isOk()) .andExpect(MockMvcResultMatchers.jsonPath(&quot;$.id&quot;).value(1)) .andExpect(MockMvcResultMatchers.jsonPath(&quot;$.name&quot;).value(&quot;台式机123&quot;)) .andDo(MockMvcResultHandlers.print()) .andReturn(); System.out.println(&quot;================================&quot;); System.out.println(result.getHandler()); &#125;&#125; SSM框架乱码解决1.请求乱码解决之get乱码问题GET请求参数是通过请求行中的URI发送给Web服务器（Tomcat）的。 Tomcat服务器会对URI进行编码操作（此时使用的是Tomcat设置的字符集，默认是iso8859-1） 到了我们的应用程序中的请求参数，已经是被Tomcat使用ISO8859-1字符集进行编码之后的了。 解决方式:(1)指定UTF-8编码，如下：1&lt;Connector URIEncoding=&quot;utf-8&quot; connectionTimeout=&quot;20000&quot; port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot; redirectPort=&quot;8443&quot;/&gt; (2)对请求参数进行重新解码12String username = new String(request.getParamter(&quot;userName&quot;).getBytes(&quot;ISO8859-1&quot;),&quot;utf-8&quot;) (3)过滤器+请求装饰器统一解决请求乱码MyRequestWrapperMyCharacterEncodingFilter详见：https://blog.csdn.net/empiresteven/article/details/497576672.请求乱码解决之post乱码问题 &lt;!-- POST乱码过滤器 --&gt; &lt;filter&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;utf-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; 3响应乱码解决使用@RequestMapping注解中的produces属性，指定响应体的编码格式","categories":[],"tags":[{"name":"SpringMVC学习（第二次）","slug":"SpringMVC学习（第二次）","permalink":"http://yoursite.com/tags/SpringMVC学习（第二次）/"}]},{"title":"SpringMVC学习（第一次）","slug":"SpringMVC学习（第一次）","date":"2019-01-08T06:23:02.000Z","updated":"2019-01-16T16:44:57.646Z","comments":true,"path":"2019/01/08/SpringMVC学习（第一次）/","link":"","permalink":"http://yoursite.com/2019/01/08/SpringMVC学习（第一次）/","excerpt":"","text":"三层架构介绍表现层： 也就是我们常说的web 层。它负责接收客户端请求，向客户端响应结果，通常客户端使用http 协议请求web 层，web 需要接收 http 请求，完成 http 响应。 表现层包括展示层和控制层：控制层负责接收请求，展示层负责结果的展示。 表现层依赖业务层，接收到客户端请求一般会调用业务层进行业务处理，并将处理结果响应给客户端。 表现层的设计一般都使用 MVC 模型。（MVC 是表现层的设计模型，和其他层没有关系） 业务层： 也就是我们常说的 service 层。它负责业务逻辑处理，和我们开发项目的需求息息相关。web 层依赖业务层，但是业务层不依赖 web 层。 业务层在业务处理时可能会依赖持久层，如果要对数据持久化需要保证事务一致性（也就是我们说的， 事务应该放到业务层来控制） 持久层： 也就是我们是常说的 dao 层。负责数据持久化，包括数据层即数据库和数据访问层，数据库是对数据进行持久化的载体，数据访问层是业务层和持久层交互的接口，业务层需要通过数据访问层将数据持久化到数据库中。通俗的讲，持久层就是和数据库交互，对数据库表进行曾删改查的 MVC设计模式MVC 全名是 Model View Controller，是模型(model)－视图(view)－控制器(controller)的缩写， 是一种用于设计创建 Web 应用程序表现层的模式。MVC 中每个部分各司其职：Model（模型）：模型包含业务模型和数据模型，数据模型用于封装数据，业务模型用于处理业务。View（视图）：通常指的就是我们的 jsp 或者 html。作用一般就是展示数据的。通常视图是依据模型数据创建的。Controller（控制器）：是应用程序中处理用户交互的部分。作用一般就是处理程序逻辑的。 SpringMVC介绍SpringMVC 是一种基于 Java 的实现 MVC 设计模型的请求驱动类型的轻量级 Web 框架，属于 SpringFrameWork 的后续产品，已经融合在 Spring Web Flow 里面。Spring 框架提供了构建 Web 应用程序的全功能 MVC 模块。使用 Spring 可插入的 MVC 架构，从而在使用 Spring 进行 WEB 开发时，可以选择使用 Spring 的 Spring MVC 框架或集成其他 MVC 开发框架，如 Struts1(现在一般不用)，Struts2 等。SpringMVC 已经成为目前最主流的 MVC 框架之一，并且随着 Spring3.0 的发布，全面超越 Struts2，成为最优秀的 MVC 框架。它通过一套注解，让一个简单的 Java 类成为处理请求的控制器，而无须实现任何接口。同时它还支持RESTful 编程风格的请求。 SpringMVC流程分析1、用户发送请求至前端控制器DispatcherServlet2、DispatcherServlet收到请求调用HandlerMapping处理器映射器。3、处理器映射器根据请求url找到具体的处理器，生成处理器对象及处理器拦截器(如果有则生成)一并返回给DispatcherServlet。4、DispatcherServlet通过HandlerAdapter处理器适配器调用处理器5、HandlerAdapter执行处理器(handler，也叫后端控制器)。6、Controller执行完成返回ModelAndView7、HandlerAdapter将handler执行结果ModelAndView返回给DispatcherServlet8、DispatcherServlet将ModelAndView传给ViewReslover视图解析器9、ViewReslover解析后返回具体View对象10、DispatcherServlet对View进行渲染视图（即将模型数据填充至视图中）。11、DispatcherServlet响应用户 SpringMVC组件DispatcherServlet：前端控制器用户请求到达前端控制器，它就相当于mvc模式中的C，dispatcherServlet是整个流程控制的中心，由它调用其它组件处理用户的请求，dispatcherServlet的存在降低了组件之间的耦合性。HandlerMapping：处理器映射器HandlerMapping负责根据用户请求找到Handler即处理器，springmvc提供了不同的映射器实现不同的映射方式，例如：配置文件方式，实现接口方式，注解方式等。Handler：处理器Handler 是继DispatcherServlet前端控制器的后端控制器，在DispatcherServlet的控制下Handler对具体的用户请求进行处理。由于Handler涉及到具体的用户业务请求，所以一般情况需要程序员根据业务需求开发Handler。HandlAdapter：处理器适配器通过HandlerAdapter对处理器进行执行，这是适配器模式的应用，通过扩展适配器可以对更多类型的处理器进行执行。View Resolver：视图解析器View Resolver负责将处理结果生成View视图，View Resolver首先根据逻辑视图名解析成物理视图名即具体的页面地址，再生成View视图对象，最后对View进行渲染将处理结果通过页面展示给用户。View：视图springmvc框架提供了很多的View视图类型的支持，包括：jstlView、freemarkerView、pdfView等。我们最常用的视图就是jsp。（一般来说需要开发的就是处理器和视图，其中处理器映射器，处理器适配器，视图解析器成为SpringMVC的三大组件）三大组件的配置：RequestMappingHandlerMapping：注解式处理器映射器对类中标记@ResquestMapping的方法进行映射，根据ResquestMapping定义的url匹配ResquestMapping标记的方法，匹配成功返回HandlerMethod对象给前端控制器，HandlerMethod对象中封装url对应的方法Method。 RequestMappingHandlerAdapter：注解式处理器适配器对标记@ResquestMapping的方法进行适配。1234&lt;!--注解映射器 --&gt;&lt;bean class=&quot;org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping&quot;/&gt;&lt;!--注解适配器 --&gt;&lt;bean class=&quot;org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter&quot;/&gt; 或者通过mvc的标签和配置&lt;mvc:annotation-drivern /&gt;，这个标签会向Spring的容器中注入很多的BeanDefinition其中包含上面的注解映射器和注解适配器 视图解析器的配置：1234567&lt;bean class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot;&gt; &lt;!-- 该视图解析器，默认的视图类就是JstlView，可以不写 --&gt; &lt;property name=&quot;viewClass&quot; value=&quot;org.springframework.web.servlet.view.JstlView&quot; /&gt; &lt;property name=&quot;prefix&quot; value=&quot;/WEB-INF/jsp/&quot; /&gt; &lt;property name=&quot;suffix&quot; value=&quot;.jsp&quot; /&gt; &lt;/bean&gt; SSM框架的整合由于整合过Spring和Mybatis，所以只贴出Springmvc.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xmlns:mvc=&quot;http://www.springframework.org/schema/mvc&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd&quot;&gt; &lt;!-- 处理器类的扫描 --&gt; &lt;context:component-scan base-package=&quot;com.kkb.ssm.controller&quot; /&gt; &lt;!-- 配置注解的适配器和映射器，同时还注入了很多其他的bean --&gt; &lt;!-- 处理器适配器会去调用conversion-service --&gt; &lt;mvc:annotation-driven conversion-service=&quot;conversionService&quot; /&gt; &lt;!-- 显式的配置视图解析器 --&gt; &lt;bean class=&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot;&gt; &lt;property name=&quot;prefix&quot; value=&quot;/WEB-INF/jsp/&quot;&gt;&lt;/property&gt; &lt;property name=&quot;suffix&quot; value=&quot;.jsp&quot;&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!-- 配置自定义的转换服务 --&gt; &lt;bean id=&quot;conversionService&quot; class=&quot;org.springframework.format.support.FormattingConversionServiceFactoryBean&quot;&gt; &lt;property name=&quot;converters&quot;&gt; &lt;set&gt; &lt;!-- 自定义日期类型转换器 --&gt; &lt;bean class=&quot;com.kkb.ssm.controller.converter.DateConverter&quot;&gt;&lt;/bean&gt; &lt;/set&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- 配置异常处理器 --&gt; &lt;bean class=&quot;com.kkb.ssm.exception.resolver.CustomExceptionResolver&quot;&gt;&lt;/bean&gt; &lt;!-- 配置多部件解析器 --&gt; &lt;bean id=&quot;multipartResolver&quot; class=&quot;org.springframework.web.multipart.commons.CommonsMultipartResolver&quot;&gt; &lt;!-- 限制上传文件的大小 单位是byte--&gt; &lt;property name=&quot;maxUploadSize&quot; value=&quot;5000000&quot;&gt;&lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 里面就是多配了日期转换器和部件解析器 Controller方法的返回值一般来说都返回一个字符串：rediect和forward的区别：redirect:相当于“response.sendRedirect()”浏览器URL发生改变Request域不能共享forward：相当于“request.getRequestDispatcher().forward(request,response)”浏览器URL不发送改变Request域可以共享比较常用的是使用注解来修饰:@ResponseBody和@RequestBodyResponseBody注解可以通过内置的9种HttpMessageConverter，匹配不同的Controller返回值类型，然后进行不同的消息转换处理。 @RequestBody注解的作用和@ResponseBody注解正好相反，它是处理请求参数的Http消息转换的。 请求参数绑定1.简单类型参数绑定方式直接绑定：需要保证http请求的key和Controller方法中的参数保持一致注解绑定：为了解决key和参数不一致的情况需要使用@RequestParam注解才能将请求参数绑定成功。2.POJO类型的参数绑定控制器方法的参数类型是 POJO 类型。要求表单中参数名称和 POJO 类的属性名称保持一致。3.绑定包装POJO包装POJO类，依然是一个POJO，只是说为了方便沟通，将POJO中包含另一个POJO的这种类，称之为包装POJO。4.POJO类型集合或者数组接收参数批量传递的请求参数，最终要使用List来接收，那么这个List必须放在另一个POJO类中。就可以用这个请求： http://localhost:8080/xxx/batchUpdateItem?itemList[0].id=1&amp; itemList[0].name=iphone&amp; itemList[0].price=1000&amp;itemList[1].id=2&amp; itemList[1]. name=iphone x&amp; itemList[1].price=2000","categories":[],"tags":[{"name":"SpringMVC学习（第一次）","slug":"SpringMVC学习（第一次）","permalink":"http://yoursite.com/tags/SpringMVC学习（第一次）/"}]},{"title":"Spring-Mybatis整合","slug":"Spring-Mybatis整合","date":"2019-01-05T17:24:48.000Z","updated":"2019-01-09T07:37:53.285Z","comments":true,"path":"2019/01/06/Spring-Mybatis整合/","link":"","permalink":"http://yoursite.com/2019/01/06/Spring-Mybatis整合/","excerpt":"","text":"整合思路Spring在java项目中，主要的责任就是对javaBean进行IoC处理（spring容器）三层结构：业务层、持久层 持久层：DataSource、SqlSessionFactory（单例管理）、MapperScannerConfigurer 业务层：Service实现类、事务管理三层架构最主要的东西还是配置文件的编写： 和数据库交互的配置文件applicationContext-dao.xml:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd&quot;&gt;&lt;!-- 读取java配置文件，替换占位符数据 --&gt;&lt;context:property-placeholder location=&quot;classpath:db.properties&quot; /&gt;&lt;!-- 配置数据源 --&gt;&lt;bean id=&quot;dataSource&quot; class=&quot;org.apache.commons.dbcp.BasicDataSource&quot; destroy-method=&quot;close&quot;&gt; &lt;property name=&quot;driverClassName&quot; value=&quot;$&#123;db.driverClassName&#125;&quot; /&gt; &lt;property name=&quot;url&quot; value=&quot;$&#123;db.url&#125;&quot; /&gt; &lt;property name=&quot;username&quot; value=&quot;$&#123;db.username&#125;&quot; /&gt; &lt;property name=&quot;password&quot; value=&quot;$&#123;db.password&#125;&quot; /&gt;&lt;/bean&gt;&lt;!-- 配置SqlSessionFactory --&gt;&lt;bean id=&quot;sqlSessionFactory&quot;class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt;&lt;!-- 注入dataSource --&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;&gt;&lt;/property&gt;&lt;!-- mybatis批量别名配置 --&gt; &lt;property name=&quot;typeAliasesPackage&quot; value=&quot;com.kkb.ms.po&quot;&gt;&lt;/property&gt; &lt;!-- 注入mybatis的全局配置文件路径 (该部分可以被省略掉) --&gt; &lt;!-- &lt;property name=&quot;configLocation&quot; value=&quot;mybatis/SqlMapConfig.xml&quot;&gt;&lt;/property&gt; --&gt;&lt;/bean&gt; &lt;!-- 相当于配置之前的AccountDao持久层bean --&gt; &lt;!-- 配置Mapper代理对象方式一：MapperFactoryBean --&gt; &lt;!-- 通过MapperFactoryBean生成的代理对象，一次只能针对一个接口进行生成 --&gt; &lt;!-- 注意事项：mapper接口类和mapper映射文件同包同名 --&gt; &lt;!-- &lt;bean id=&quot;accountMapper&quot; class=&quot;org.mybatis.spring.mapper.MapperFactoryBean&quot;&gt; 注入SqlSessionFactory &lt;property name=&quot;sqlSessionFactory&quot; ref=&quot;sqlSessionFactory&quot;&gt;&lt;/property&gt; 注入目标接口类 &lt;property name=&quot;mapperInterface&quot; value=&quot;com.kkb.ms.mapper.AccountMapper&quot;&gt;&lt;/property&gt; &lt;/bean&gt; --&gt; &lt;!-- 配置Mapper代理对象方式二：MapperScannerConfigurer --&gt; &lt;!-- 批量代理对象的生成 --&gt; &lt;bean class=&quot;org.mybatis.spring.mapper.MapperScannerConfigurer&quot;&gt; &lt;!-- 指定需要生成代理的接口所在的包名 --&gt; &lt;property name=&quot;basePackage&quot; value=&quot;com.kkb.ms.mapper&quot;&gt;&lt;/property&gt; &lt;!-- 注意事项：不要配置SqlSessionFactory --&gt; &lt;!-- &lt;property name=&quot;sqlSessionFactory&quot; ref=&quot;sqlSessionFactory&quot;&gt;&lt;/property&gt; --&gt; &lt;property name=&quot;sqlSessionFactoryBeanName&quot; value=&quot;sqlSessionFactory&quot;&gt;&lt;/property&gt;&lt;/bean&gt;&lt;/beans&gt; applicationContext-services.xml:123456789101112131415&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;com.kkb.ms.mapper.AccountMapper&quot;&gt; &lt;!-- 查询 --&gt; &lt;select id=&quot;queryMoney&quot; parameterType=&quot;string&quot; resultType=&quot;double&quot;&gt; SELECT money FROM testms WHERE name = #&#123;name&#125; &lt;/select&gt; &lt;!-- 修改 --&gt; &lt;update id=&quot;update&quot; parameterType=&quot;map&quot;&gt; UPDATE testms SET money = #&#123;money&#125; WHERE name = #&#123;name&#125; &lt;/update&gt;&lt;/mapper&gt; applicationContext-services.xml: (事务处理)123456789101112131415161718192021222324252627282930313233343536373839404142&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xmlns:tx=&quot;http://www.springframework.org/schema/tx&quot; xmlns:aop=&quot;http://www.springframework.org/schema/aop&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd&quot;&gt;&lt;!-- 配置平台事务管理器 --&gt;&lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!-- 事务通知 --&gt;&lt;!-- tx:advice：对应的处理器类就是TransactionInterceptor类（实现了MethodInterceptor） --&gt;&lt;!-- TransactionInterceptor类实现事务是通过transaction-manager属性指定的值进行事务管理 --&gt;&lt;tx:advice id=&quot;txAdvice&quot; transaction-manager=&quot;transactionManager&quot;&gt; &lt;!-- 设置事务管理信息 --&gt; &lt;tx:attributes&gt; &lt;!-- 增删改使用REQUIRED事务传播行为 --&gt; &lt;!-- 查询使用read-only --&gt; &lt;tx:method name=&quot;transfer*&quot; propagation=&quot;REQUIRED&quot; isolation=&quot;DEFAULT&quot; /&gt; &lt;/tx:attributes&gt;&lt;/tx:advice&gt;&lt;!-- 基于AspectJ + XML方式实现声明式事务 --&gt;&lt;aop:config&gt; &lt;!-- aop:advisor标签使用的是传统spring aop开发方式实现的 --&gt; &lt;!-- spring已经实现了该增强功能，spring使用的是实现MethodInterceptor接口的方式实现的 --&gt; &lt;aop:advisor advice-ref=&quot;txAdvice&quot; pointcut=&quot;execution(* *..*.*ServiceImpl.*(..))&quot; /&gt;&lt;/aop:config&gt;w&lt;/beans&gt; Dao层：12345678910package com.kkb.ms.mapper;import org.apache.ibatis.annotations.Param;public interface AccountMapper &#123; void update(@Param(&quot;name&quot;) String name, @Param(&quot;money&quot;)double money); double queryMoney(String name);&#125; 123456789101112131415&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;com.kkb.ms.mapper.AccountMapper&quot;&gt; &lt;!-- 查询 --&gt; &lt;select id=&quot;queryMoney&quot; parameterType=&quot;string&quot; resultType=&quot;double&quot;&gt; SELECT money FROM testms WHERE name = #&#123;name&#125; &lt;/select&gt; &lt;!-- 修改 --&gt; &lt;update id=&quot;update&quot; parameterType=&quot;map&quot;&gt; UPDATE testms SET money = #&#123;money&#125; WHERE name = #&#123;name&#125; &lt;/update&gt;&lt;/mapper&gt; Services层（实现转账的业务）123456package com.kkb.ms.service;public interface AccountService &#123; void transfer(String from , String to,double money);&#125; 1234567891011121314151617181920212223242526package com.kkb.ms.test;import javax.annotation.Resource;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.test.context.ContextConfiguration;import org.springframework.test.context.junit4.SpringJUnit4ClassRunner;import com.kkb.ms.service.AccountService;@RunWith(SpringJUnit4ClassRunner.class)//@ContextConfiguration(locations = &#123; &quot;classpath:spring/applicationContext-dao.xml&quot;, &quot;classpath:spring/applicationContext-service.xml&quot;,// &quot;classpath:spring/applicationContext-tx.xml&quot; &#125;)@ContextConfiguration(locations = &quot;classpath:spring/applicationContext-*.xml&quot; )public class AccountServiceTest &#123; @Resource private AccountService service; @Test public void testTransfer() &#123; service.transfer(&quot;老公&quot;, &quot;老婆&quot;, 100); &#125;&#125;","categories":[],"tags":[{"name":"Spring-Mybatis整合","slug":"Spring-Mybatis整合","permalink":"http://yoursite.com/tags/Spring-Mybatis整合/"}]},{"title":"Spring组件学习","slug":"Spring组件学习","date":"2019-01-05T09:24:35.000Z","updated":"2019-01-09T07:39:31.975Z","comments":true,"path":"2019/01/05/Spring组件学习/","link":"","permalink":"http://yoursite.com/2019/01/05/Spring组件学习/","excerpt":"","text":"Spring组件学习一.Spring应用之SpringJdbc实现：1.引入相关的jar包12345&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;5.0.7.RELEASE&lt;/version&gt;&lt;/dependency&gt; 2.对Spring配置文件进行Spring的配置（数据库连接池写了两种一种是内置的数据库连接池一种是DBCP连接池）12345678910111213141516171819202122232425&lt;!-- 管理spring内置的DataSource --&gt; &lt;!-- &lt;bean id=&quot;dataSource&quot; --&gt; &lt;!-- class=&quot;org.springframework.jdbc.datasource.DriverManagerDataSource&quot;&gt; --&gt; &lt;!-- set方法注入属性，和类中的成员属性无关，和set方法名称有关，比如有个属性叫username，但是set方法：setName --&gt; &lt;!-- &lt;property name=&quot;driverClassName&quot; --&gt; &lt;!-- value=&quot;com.mysql.jdbc.Driver&quot; /&gt; --&gt; &lt;!-- &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql:///kkb&quot; /&gt; --&gt; &lt;!-- &lt;property name=&quot;username&quot; value=&quot;root&quot; /&gt; --&gt; &lt;!-- &lt;property name=&quot;password&quot; value=&quot;root&quot; /&gt; --&gt; &lt;!-- &lt;/bean&gt; --&gt; &lt;!-- 管理第三方的DataSource --&gt;&lt;bean id=&quot;dataSource&quot; class=&quot;org.apache.commons.dbcp.BasicDataSource&quot; destroy-method=&quot;close&quot;&gt;&lt;!-- set方法注入属性，和类中的成员属性无关，和set方法名称有关，比如有个属性叫username，但是set方法：setName --&gt; &lt;property name=&quot;driverClassName&quot; value=&quot;com.mysql.jdbc.Driver&quot; /&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql://localhost:3306/jdbctest?useUnicode=true&quot; /&gt; &lt;property name=&quot;username&quot; value=&quot;root&quot; /&gt; &lt;property name=&quot;password&quot; value=&quot;19980825&quot; /&gt;&lt;/bean&gt;&lt;!-- 管理JdbcTemplate --&gt;&lt;bean id=&quot;template&quot; class=&quot;org.springframework.jdbc.core.JdbcTemplate&quot;&gt; &lt;constructor-arg name=&quot;dataSource&quot; ref=&quot;dataSource&quot;&gt;&lt;/constructor-arg&gt;&lt;/bean&gt; 3.用Spring整合Junit的方式进行测试12345678910111213141516171819202122232425262728293031323334@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = &quot;classpath:spring.xml&quot;)public class TestJdbcTemplate2 &#123; @Autowired private JdbcTemplate jdbcTemplate; @Test public void test() &#123; // 完成数据的添加 //jdbcTemplate.update(&quot;insert into blog values(6,&quot;学习&quot;,&quot;张红&quot;,7,2019-1-3)&quot;); &#125; @Test public void test2() &#123; // 第一个参数：要执行的SQL语句 // 第二个参数：结果映射处理器（RowMapper） // 第三个参数：SQL语句中的入参 List&lt;Account&gt; aList = jdbcTemplate.query(&quot;SELECT * FROM account&quot;, new MyBeanMapper(), null); System.out.println(aList); &#125;&#125;/** * 结果映射器 * @author think * */class MyBeanMapper implements RowMapper &#123; @Override public Account mapRow(ResultSet rs, int rowNum) throws SQLException &#123; Account account = new Account(); account.setId(rs.getInt(&quot;id&quot;)); account.setName(rs.getString(&quot;name&quot;)); account.setMoney(rs.getDouble(&quot;money&quot;)); return account; &#125;&#125; 二.Spring应用之SpringJdbcDaoSupportJdbcDaoSupport是JDBC数据访问对象的超类。它与特定的数据源相关联。Spring Inversion of Control （IOC）容器或BeanFactory负责获得相应数据源的配置详细信息，并将其与JdbcDaoSupport相关联。这个类最重要的功能就是使子类可以使用JdbcTemplate对象。SpringJdbcDaoSupport就是里面内置了JdbcTemplate对象，我们只需要在dao层继承这个SpringJdbcDaoSupport 但是在配置文件中必须对JdbcTemple进行管理1.引入相关的jar包2.配置文件的相关配置123456789101112131415161718192021&lt;!-- 从底层往上层配置 --&gt;&lt;!-- 管理第三方的DataSource --&gt;&lt;bean id=&quot;dataSource&quot; class=&quot;org.apache.commons.dbcp.BasicDataSource&quot; destroy-method=&quot;close&quot;&gt;&lt;!-- set方法注入属性，和类中的成员属性无关，和set方法名称有关，比如有个属性叫username，但是set方法：setName --&gt; &lt;property name=&quot;driverClassName&quot; value=&quot;com.mysql.jdbc.Driver&quot; /&gt; &lt;property name=&quot;url&quot; value=&quot;jdbc:mysql:///kkb&quot; /&gt; &lt;property name=&quot;username&quot; value=&quot;root&quot; /&gt; &lt;property name=&quot;password&quot; value=&quot;root&quot; /&gt;&lt;/bean&gt;&lt;!-- 管理JdbcTemplate --&gt;&lt;bean id=&quot;template&quot; class=&quot;org.springframework.jdbc.core.JdbcTemplate&quot;&gt; &lt;constructor-arg name=&quot;dataSource&quot; ref=&quot;dataSource&quot;&gt;&lt;/constructor-arg&gt;&lt;/bean&gt;&lt;!--配置 AccountDao 和AccountService --&gt;&lt;context:component-scan base-package=&quot;com.kkb.spring.service&quot;&gt;&lt;/context:component-scan&gt; &lt;bean id=&quot;accountDao&quot; class=&quot;com.kkb.spring.dao.AccountDaoImpl&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot; /&gt;&lt;/bean&gt; 3.服务层（ServiceImpl）123456789101112131415161718192021222324//@Transactional：标记该类的所有方法都已经被事务进行管理了，至于管理属性，不设置的话，都采取默认值@Transactional@Servicepublic class AccountServiceImpl implements AccountService &#123; @Resource private AccountDao accountDao; @Override public void transfer(String from, String to, double money) &#123; // 先查询from账户的钱 double fromMoney = accountDao.queryMoney(from); // 对from账户进行扣钱操作 accountDao.update(from, fromMoney - money); //手动制造异常 System.out.println(1/0); // 先查询from账户的钱 double toMoney = accountDao.queryMoney(to); // 对to账户进行加钱操作 accountDao.update(to, toMoney + money); &#125;&#125; 4.Dao层123456789101112131415161718192021222324252627@Repositorypublic class AccountDaoImpl extends JdbcDaoSupport implements AccountDao &#123; // JDBC操作 // Mybatis操作 // JdbcTemplate操作 // @Resource // private JdbcTemplate jdbcTemplate; @Override public void update(String name, double money) &#123; Object[] args = &#123; money, name &#125;; // jdbcTemplate.update(&quot;UPDATE account SET money = ? WHERE name = ? &quot;, args); this.getJdbcTemplate().update(&quot;UPDATE account SET money = ? WHERE name = ? &quot;, args); &#125; @Override public double queryMoney(String name) &#123; // Double money = jdbcTemplate.queryForObject(&quot;SELECT money FROM account WHERE // name = ?&quot;, new DoubleMapper(), // name); Double money = this.getJdbcTemplate().queryForObject(&quot;SELECT money FROM account WHERE name = ?&quot;, new DoubleMapper(), name); return money; &#125;&#125; 三.Spring应用之Spring事务管理事务的特性（ACID）：原子性：原子性是指事务包含的所有操作要么全部成功，要么全部失败回滚。一致性：一致性是指事务必须使数据库从一个一致性状态变换到另一个一致性状态，也就是说一个事务执行之前和执行之后都必须处于一致性状态。拿转账来说，假设用户A和用户B两者的钱加起来一共是5000，那么不管A和B之间如何转账，转几次账，事务结束后两个用户的钱相加起来应该还得是5000，这就是事务的一致性。隔离性：隔离性是当多个用户并发访问数据库时，比如操作同一张表时，数据库为每一个用户开启的事务，不能被其他事务的操作所干扰，多个并发事务之间要相互隔离。持久性：持久性是指一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作。 事务并发问题（隔离性导致）：在事务的并发操作中可能会出现一些问题：脏读：一个事务读取到另一个事务未提交的数据。不可重复读：一个事务因读取到另一个事务已提交的数据。导致对同一条记录读取两次以上的结果不一致。update操作幻读：一个事务因读取到另一个事务已提交的数据。导致对同一张表读取两次以上的结果不一致。insert、delete操作 四种隔离级别：现在来看看MySQL数据库为我们提供的四种隔离级别（由低到高）：①Read uncommitted (读未提交)：最低级别，任何情况都无法保证。②Read committed (读已提交)：可避免脏读的发生。③Repeatable read (可重复读)：可避免脏读、不可重复读的发生。④Serializable (串行化)：可避免脏读、不可重复读、幻读的发生。大多数数据库的默认隔离级别是Read committed，比如Oracle、DB2等。MySQL数据库的默认隔离级别是Repeatable read。 Spring并不直接管理事务，而是提供了多种事务管理器，他们将事务管理的职责委托给Hibernate或者JTA等持久化机制所提供的相关平台框架的事务来实现。 Spring事务管理器的接口是PlatformTransactionManager，通过这个接口，Spring为各个平台如JDBC、Hibernate等都提供了对应的事务管理器，但是具体的实现就是各个平台自己的事情了。 PlatformTransactionManager接口 – 平台事务管理器.(真正管理事务的类)。该接口有具体的实现类，根据不同的持久层框架，需要选择不同的实现类！ TransactionDefinition接口 – 事务定义信息.(事务的隔离级别,传播行为,超时,只读)这个接口里面有两个重要的参数 一个是事务隔离级别的常量 另外一个是事务的传播行为常量（主要为了解决services层方法之间相互调用的问题 保证不同的services层方法之间的调用由同一个事务进行管理） TransactionStatus接口 – 事务的状态（是否新事务、是否已提交、是否有保存点、是否回滚） Spring的声明式事务管理： (基于AspectJ的xml方式)1.配置文件的配置：123456789101112131415161718192021&lt;!-- 配置平台事务管理器 --&gt;&lt;bean id=&quot;transactionManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!-- 事务通知 --&gt;&lt;!-- tx:advice：对应的处理器类就是TransactionInterceptor类（实现了MethodInterceptor） --&gt;&lt;!-- TransactionInterceptor类实现事务是通过transaction-manager属性指定的值进行事务管理 --&gt;&lt;tx:advice id=&quot;txAdvice&quot; transaction-manager=&quot;transactionManager&quot;&gt;&lt;!-- 设置事务管理信息 --&gt; &lt;tx:attributes&gt; &lt;!-- 增删改使用REQUIRED事务传播行为 --&gt; &lt;!-- 查询使用read-only --&gt; &lt;tx:method name=&quot;transfer*&quot; propagation=&quot;REQUIRED&quot; isolation=&quot;DEFAULT&quot;/&gt; &lt;/tx:attributes&gt;&lt;/tx:advice&gt;&lt;!-- 基于AspectJ + XML方式实现声明式事务 --&gt;&lt;aop:config&gt;&lt;!-- aop:advisor标签使用的是传统spring aop开发方式实现的 --&gt;&lt;!-- spring已经实现了该增强功能，spring使用的是实现MethodInterceptor接口的方式实现的 --&gt; &lt;aop:advisor advice-ref=&quot;txAdvice&quot; pointcut=&quot;execution(* *..*.*ServiceImpl.*(..))&quot;/&gt;&lt;/aop:config&gt; 2.Services层代码12345678910111213141516171819202122232425//@Transactional：标记该类的所有方法都已经被事务进行管理了，至于管理属性，不设置的话，都采取默认值@Transactional@Servicepublic class AccountServiceImpl implements AccountService &#123; @Resource private AccountDao accountDao; @Override public void transfer(String from, String to, double money) &#123; // 先查询from账户的钱 double fromMoney = accountDao.queryMoney(from); // 对from账户进行扣钱操作 accountDao.update(from, fromMoney - money); //手动制造异常 System.out.println(1/0); // 先查询from账户的钱 double toMoney = accountDao.queryMoney(to); // 对to账户进行加钱操作 accountDao.update(to, toMoney + money); &#125;&#125;","categories":[],"tags":[{"name":"Spring组件学习","slug":"Spring组件学习","permalink":"http://yoursite.com/tags/Spring组件学习/"}]},{"title":"Spring知识点总结（一）","slug":"Spring知识点总结（一）","date":"2019-01-02T15:16:23.000Z","updated":"2019-01-05T13:13:33.625Z","comments":true,"path":"2019/01/02/Spring知识点总结（一）/","link":"","permalink":"http://yoursite.com/2019/01/02/Spring知识点总结（一）/","excerpt":"","text":"SpringIoc：1.什么是Ioc容器：所谓的IoC容器就是指的Spring中Bean工厂里面的Map存储结构（存储了Bean的实例）。2.Spring中的框架工厂：ApplicationContext接口（）：实现了BeanFactory接口 实现ApplicationContext接口的工厂，可以获取到容器中具体的Bean对象BeanFactory工厂（是Spring框架早期的创建Bean对象的工厂接口）：其实通过源码分析，不管是BeanFactory还是ApplicationContext，其实最终的底层BeanFactory都是DefaultListableBeanFactory3.ApplicationContext和BeanFactory的区别？创建Bean对象的时机不同:BeanFactory采取延迟加载，第一次getBean时才会初始化Bean。ApplicationContext是加载完applicationContext.xml时，就创建具体的Bean对象的实例。（只对BeanDefition中描述为是单例的bean，才进行饿汉式加载）4.Web应用中创建IoC容器：1）web服务器（tomcat）启动会加载web.xml（启动ContextLoaderListener监听器，实现了ServletContextListener接口）2）ContextLoaderListener监听器会在web容器启动的时候，触发contextInitialized()3）contextInitialized()方法会调用initWebApplicationContext()方法，该方法负责创建Spring容器（DefaultListableBeanFactory）。4）ContextLoader类中创建Spring容器并初始化容器中的Bean实例5）最终调用configureAndRefreshWebApplicationContext方法中调用最终初始化Bean的refresh方法5.bean标签作用：用于配置对象让 spring 来创建的。默认情况下它调用的是类中的无参构造函数。如果没有无参构造函数则不能创建成功。id：给对象在容器中提供一个唯一标识。用于获取对象。class：指定类的全限定类名。用于反射创建对象。默认情况下调用无参构造函数。scope：指定对象的作用范围6.bean的作用范围：单例对象：scope=”singleton”一个应用只有一个对象的实例。它的作用范围就是整个引用。生命周期：对象出生：当应用加载，创建容器时，对象就被创建了。对象活着：只要容器在，对象一直活着。对象死亡：当应用卸载，销毁容器时，对象就被销毁了。多例对象：scope=”prototype”每次访问对象时，都会重新创建对象实例。生命周期：对象出生：当使用对象时，创建新的对象实例。对象活着：只要对象在使用中，就一直活着。对象死亡：当对象长时间不用时，被 java 的垃圾回收器回收了。7.实例化bean的三种方式?第一种：使用默认无参构造函数（重点）如果 bean 中没有默认无参构造函数，将会创建失败第二种：静态工厂（了解）模拟一个静态工厂，创建业务层实现类public class StaticFactory {public static UserService createUserService(){return new UserServiceImpl();}} 使用 StaticFactory 类中的静态方法 createUserService 创建对象，并存入 spring 容器 id 属性：指定 bean 的 id，用于从容器中获取 class 属性：指定静态工厂的全限定类名 factory-method 属性：指定生产对象的静态方法第三种：实例工厂（了解）拟一个实例工厂，创建业务层实现类 此工厂创建对象，必须现有工厂实例对象，再调用方法此种方式是：先把工厂的创建交给 spring 来管理。 然后在使用工厂的 bean 来调用里面的方法 factory-bean 属性：用于指定实例工厂 bean 的 id。 factory-method 属性：用于指定实例工厂中创建对象的方法。8.Spring依赖注入什么是依赖？依赖指的就是Bean实例中的属性属性分为：简单类型（8种基本类型和String类型）的属性、POJO类型的属性、集合数组类型的属性。什么是依赖注入？依赖注入：Dependency Injection。它是 spring 框架核心 ioc 的具体实现。为什么要进行依赖注入？我们的程序在编写时，通过控制反转，把对象的创建交给了 spring，但是代码中不可能出现没有依赖的情况。ioc 解耦只是降低他们的依赖关系，但不会消除。例如：我们的业务层仍会调用持久层的方法。那这种业务层和持久层的依赖关系，在使用 spring 之后，就让 spring 来维护了。简单的说，就是坐等框架把持久层对象传入业务层，而不用我们自己去获取9.Spring依赖注入的方式1）构造函数注入2）set方法注入（重点） set方法注入又分为手动装配方式注入和自动装配方式注入。手动装配方式（XML方式）：bean标签的子标签property，需要在类中指定set方法。自动装配方式（注解方式）：@Autowired注解、@Resource注解。@Autowired：一部分功能是查找实例，从spring容器中根据类型（java类）获取对应的实例。另一部分功能就是赋值，将找到的实例，装配给另一个实例的属性值。（注意事项：一个java类型在同一个spring容器中，只能有一个实例）@Resource：一部分功能是查找实例，从spring容器中根据Bean的名称（bean标签的名称）获取对应的实例。另一部分功能就是赋值，将找到的实例，装配给另一个实例的属性值。10.依赖注入不同类型的属性（基于XML）简单类型（value）引用类型（ref）集合类型（数组） 数组或者List集合， Set集合 Map集合 Properties集合的方式11.依赖注入常用注解?@Component 把资源让 spring 来管理。相当于在 xml 中配置一个 bean。 @Controller、@Service、@Repository注解 是@Component的衍生注解?@Autowired默认按类型装配（byType）这个注解是spring自身的默认情况下必须要求依赖对象必须存在，如果要允许null值，可以设置它的required属性为false，如：@Autowired(required=false)如果我们想使用名称装配可以结合@Qualifier注解进行使用?@Resource默认按照名称（byName）进行装配，名称可以通过name属性进行指定如果没有指定name属性，当注解写在字段上时，默认取字段名进行按照名称查找，当找不到与名称匹配的bean时才按照类型进行装配。12.Spring整合junit第一步：添加依赖 添加spring-test包即可。第二步：通过@RunWith注解，指定spring的运行器 Spring的运行器是SpringJunit4ClassRunner第三步：通过@ContextConfiguration注解，指定spring运行器需要的配置文件路径第四步：通过@Autowired注解给测试类中的变量注入数据13SpringAop的作用及优势是什么？作用：AOP采取横向抽取机制，取代了传统纵向继承体系重复性代码（性能监视、事务管理、安全检查、缓存）在程序运行期间，不修改源码对已有方法进行增强。将业务逻辑和系统处理的代码（关闭连接、事务管理、操作日志记录）解耦。优势：减少重复代码提高开发效率维护方便14.AOP相关术语介绍 Joinpoint(连接点) – 所谓连接点是指那些被拦截到的点。在spring中,这些点指的是方法,因为spring只支持方法类型的连接点 Pointcut(切入点) – 所谓切入点是指我们要对哪些Joinpoint进行拦截的定义 Advice(通知/增强) – 所谓通知是指拦截到Joinpoint之后所要做的事情就是通知.通知分为前置通知,后置通知,异常通知,最终通知,环绕通知(切面要完成的功能) Introduction(引介) – 引介是一种特殊的通知在不修改类代码的前提下, Introduction可以在运行期为类动态地添加一些方法或Field Target(目标对象) – 代理的目标对象 Weaving(织入) – 是指把增强应用到目标对象来创建新的代理对象的过程 Proxy（代理） – 一个类被AOP织入增强后，就产生一个结果代理类 Aspect(切面) – 是切入点和通知的结合，以后咱们自己来编写和配置的15.AOP实现之AspectJ（了解）AspectJ是一个java实现的AOP框架，它能够对java代码进行AOP编译（一般在编译期进行），让java代码具有AspectJ的AOP功能（当然需要特殊的编译器）可以这样说AspectJ是目前实现AOP框架中最成熟，功能最丰富的语言，更幸运的是，AspectJ与java程序完全兼容，几乎是无缝关联，因此对于有java编程基础的工程师，上手和使用都非常容易。了解AspectJ应用到java代码的过程（这个过程称为织入），对于织入这个概念，可以简单理解为aspect(切面)应用到目标函数(类)的过程。对于这个过程，一般分为动态织入和静态织入，动态织入的方式是在运行时动态将要增强的代码织入到目标类中，这样往往是通过动态代理技术完成的，如Java JDK的动态代理(Proxy，底层通过反射实现)或者CGLIB的动态代理(底层通过继承实现)，Spring AOP采用的就是基于运行时增强的代理技术ApectJ采用的就是静态织入的方式。ApectJ主要采用的是编译期织入，在这个期间使用AspectJ的acj编译器(类似javac)把aspect类编译成class字节码后，在java目标类编译时织入，即先编译aspect类再编译目标类。16.Spring AOP是通过动态代理技术实现的而动态代理是基于反射设计的。（关于反射的知识，请自行学习）动态代理技术的实现方式有两种：基于接口的JDK动态代理和基于继承的CGLib动态代理。JDK动态代理：目标对象必须实现接口CGLib动态代理：目标对象不需要实现接口，底层是通过继承目标对象产生代理子对象（代理子对象中继承了目标对象的方法，并可以对该方法进行增强）17.基于AspectJ的XML实现和基于AspectJ的注解实现（源码就不贴了）18.SpringAop通知类型通知类型（五种）：前置通知、后置通知、最终通知、环绕通知、异常抛出通知。前置通知：执行时机：目标对象方法之前执行通知配置文件：&lt;aop:before method=”before” pointcut-ref=”myPointcut”/&gt;应用场景：方法开始时可以进行校验后置通知：执行时机：目标对象方法之后执行通知，有异常则不执行了配置文件：&lt;aop:after-returning method=”afterReturning” pointcut-ref=”myPointcut”/&gt;应用场景：可以修改方法的返回值最终通知：执行时机：目标对象方法之后执行通知，有没有异常都会执行配置文件：&lt;aop:after method=”after” pointcut-ref=”myPointcut”/&gt;应用场景：例如像释放资源环绕通知：执行时机：目标对象方法之前和之后都会执行。配置文件：&lt;aop:around method=”around” pointcut-ref=”myPointcut”/&gt;应用场景：事务、统计代码执行时机异常抛出通知：执行时机：在抛出异常后通知配置文件：&lt;aop:after-throwing method=” afterThrowing “ pointcut- ref=”myPointcut”/&gt;应用场景：包装异常","categories":[],"tags":[{"name":"Spring知识点总结（一）","slug":"Spring知识点总结（一）","permalink":"http://yoursite.com/tags/Spring知识点总结（一）/"}]},{"title":"SpringIoc源码分析（一）","slug":"SpringIoc源码分析（一）","date":"2018-12-27T12:03:38.000Z","updated":"2019-01-02T15:25:17.180Z","comments":true,"path":"2018/12/27/SpringIoc源码分析（一）/","link":"","permalink":"http://yoursite.com/2018/12/27/SpringIoc源码分析（一）/","excerpt":"","text":"IoC 全称为 Inversion of Control，翻译为 “控制反转”，它还有一个别名为 DI（Dependency Injection）,即依赖注入。谁控制谁：在传统的开发模式下，我们都是采用直接 new 一个对象的方式来创建对象，也就是说你依赖的对象直接由你自己控制，但是有了 IOC 容器后，则直接由 IoC 容器来控制。所以“谁控制谁”，当然是 IoC 容器控制对象。控制什么：控制对象。为何是反转：没有 IoC 的时候我们都是在自己对象中主动去创建被依赖的对象，这是正转。但是有了 IoC 后，所依赖的对象直接由 IoC 容器创建后注入到被注入的对象中，依赖的对象由原来的主动获取变成被动接受，所以是反转。哪些方面反转了：所依赖对象的获取被反转了。IOC Service Provider 为被注入对象提供被依赖对象也有如下几种方式：构造方法注入、stter方法注入、接口注入。构造器注入，顾名思义就是被注入的对象通过在其构造方法中声明依赖对象的参数列表，让外部知道它需要哪些依赖对象。对于 JavaBean 对象而言，我们一般都是通过 getter 和 setter 方法来访问和设置对象的属性。所以，当前对象只需要为其所依赖的对象提供相对应的 setter 方法，就可以通过该方法将相应的依赖对象设置到被注入对象中。接口方式注入显得比较霸道，因为它需要被依赖的对象实现不必要的接口，带有侵入性。一般都不推荐这种方式。Spring IoC容器的初始化过程主要包括以下几个步骤：1.获取Resouce实例。加载XML配置文件，封装成Resouce实例。这时Resouce实例中已经有了配置文件的路径等信息。2.获取Document实例。通过Resource，读取XML配置文件，封装成Document实例。这时Document实例中已经有了配置文件中的标签。3.获取BeanDefinition实例。解析Document实例中的标签，最终获得BeanDefinition实例。这时BeanDefinition实例中已经有了bean的id、name、alias、class等信息。4.注册BeanDefinition。这个注册过程把BeanDefinition向IOC容器进行注册，相当于将bean的name作为key，BeanDefinition作为value，放入一个map中。IOC容器初始化过程一般不包含Bean加载的实现。Bean加载一般发生在应用第一次通过getBean向容器索取Bean的时候。但有一个例外：如果在XML文件中为Bean定义了lazy-init属性，那么Bean的加载在IOC容器初始化时就预先完成了。SpringIoc容器的bean的加载步骤总结如下：1.获取bean的真正名字（name可能是别名或者FactoryBean）。2.尝试从缓存中加载单例bean。单例bean在同一个Spring容器中只创建一次，获取bean的时候，尝试从缓存加载bean。首先从一级缓存singletonObjects中获取，如果没有获取到，且bean正在创建过程中 （isSingletonCurrentlyInCreation()为true），则尝试从二级缓存earlySingletonObjects中获取，如果还获取不到，就求助于三级缓存singletonFactories。因为spring创建单例bean的时候，存在循环依赖的问题。比如创建bean a的时候发现bean a引用了bean b，此时会去创建bean b，但又发现bean b引用了bean c，所以此时会去创建bean c，在创建bean c的过程中发现bean c引用bean a。为了避免循环依赖，Spring采取了一种将正在创建的bean实例提早暴露加入到singletonFactories缓存中，一旦下一个bean创建的时候需要依赖上个bean，则直接使用singletonFactories来获取bean。提前暴露bean实例到缓存的时机是在bean实例创建（调用构造方法）之后，初始化bean实例（属性注入）之前3.如果从缓存中加载到了单例bean，从bean实例中获取对象并返回。从缓存中加载到的bean并不一定是我们最终想要的bean。 BeanFactory是用于管理bean的一个工厂。FactoryBean是一种特殊的bean。在BeanFactory中管理两种bean，一种是标准的Java bean，另一种实现了FactoryBean接口的bean。通过beanFactory.getBean(beanName)从BeanFactory获取bean实例时，对于标准的Java bean，返回的是类自身的实例。而对于FactoryBean，返回的不是自身的实例，而是该FactoryBean的getObject方法所返回的实例。如果想要获取FactoryBean的实例，可以通过getBean(&amp;+beanName)这种方法来获取。4.原型模式的依赖检查。prototype的Bean，Spring容器不进行缓存。如果是prototype的Bean处于正在创建的状态，直接抛出异常。5.递归加载依赖的bean。如果此bean依赖了其他的bean，则需要递归加载依赖的bean。6.因为在缓存中没有加载到单例bean。 如果是单例模式，创建单例bean。如果是原型模式，创建原型bean。1.清除缓存。如果是bean是单例bean，需要首先清除缓存。2.创建bean实例。在spring中有三中实例化bean的方式：1)使用构造器实例化；采用这种实例化方式要注意的是：要实例化的类中如果有构造器的话，一定要有一个无参的构造器。2)使用静态工厂方法实例化；3)使用实例化工厂方法实例化。3.避免循环依赖。为了避免循环依赖，可以在 bean初始化完成前将创建实例的 ObjectFactory加入工厂。4.属性注入。将所有属性填充至bean的实例中。5.初始化bean。6.循环依赖检查。Sping 中解决循环依赖只对单例有效，而对于prototype的bean，Spring 没有好的解决办法，唯一要做的就是抛出异常。在这个步骤里面会检测已经加载的 bean 是否已经出现了依赖循环，并判断是否需要抛出异常。7.注册DisposableBean。8.完成创建并返回。bean的生命周期1.实例化。Spring对Bean进行实例化（默认是单例）2.属性注入。Spring将值和Bean的引用注入进Bean对应的属性中3.3初始化。如果Bean实现了BeanNameAware接口，Spring将Bean的ID传递给setBeanName()方法。如果Bean实现了BeanFactoryAware接口，Spring将调用setBeanDactory(BeanFactory bf)方法并把BeanFactory容器实例作为参数传入。如果Bean实现了ApplicationContextAwaer接口，Spring容器将调用setApplicationContext(ApplicationContext ctx)方法，把应用上下文作为参数传入。如果Bean实现了BeanPostProcess接口，Spring将调用它们的postProcessBeforeInitialization方法。如果Bean实现了InitializingBean接口，Spring将调用它们的afterPropertiesSet方法，作用与在配置文件中对Bean使用init-method声明初始化的作用一样，都是在Bean的全部属性设置成功后执行的初始化方法。如果Bean实现了BeanPostProcess接口，Spring将调用它们的postProcessAfterInitialization方法。4.注册DispostbleBean。5.经过以上的工作后，Bean将一直驻留在应用上下文中给应用使用，直到应用上下文被销毁。Bean实例销毁前，如果Bean实现了DispostbleBean接口，Spring将调用它的destory方法。 Spring单例对象的初始化其实可以分为三步：（实例化、填充属性、初始化）这样做有什么好处呢？让我们来分析一下“A的某个field或者setter依赖了B的实例对象，同时B的某个field或者setter依赖了A的实例对象”这种循环依赖的情况。A首先完成了初始化的第一步，并且将自己提前曝光到singletonFactories中，此时进行初始化的第二步，发现自己依赖对象B，此时就尝试去get(B)，发现B还没有被create，所以走create流程，B在初始化第一步的时候发现自己依赖了对象A，于是尝试get(A)，尝试一级缓存singletonObjects(肯定没有，因为A还没初始化完全)，尝试二级缓存earlySingletonObjects（也没有），尝试三级缓存singletonFactories，由于A通过ObjectFactory将自己提前曝光了，所以B能够通过ObjectFactory.getObject拿到A对象(虽然A还没有初始化完全，但是总比没有好呀)，B拿到A对象后顺利完成了初始化阶段1、2、3，完全初始化之后将自己放入到一级缓存singletonObjects中。此时返回A中，A此时能拿到B的对象顺利完成自己的初始化阶段2、3，最终A也完成了初始化，长大成人，进去了一级缓存singletonObjects中，","categories":[],"tags":[{"name":"SpringIoc源码分析（一）","slug":"SpringIoc源码分析（一）","permalink":"http://yoursite.com/tags/SpringIoc源码分析（一）/"}]},{"title":"Mybatis源码分析（三）","slug":"Mybatis源码分析（三）","date":"2018-12-26T14:11:41.000Z","updated":"2018-12-27T12:08:20.729Z","comments":true,"path":"2018/12/26/Mybatis源码分析（三）/","link":"","permalink":"http://yoursite.com/2018/12/26/Mybatis源码分析（三）/","excerpt":"","text":"动态sql标签—-for eachfor each标签的主要参数：item index collection open seperator closeitem：表示集合中示每一个元素进行迭代时的别名index：表示集合中元素进行迭代时的位置collection：表示传入参数的类型open/close：表示以什么开始以什么结束sepeator：表示每次迭代之间以什么作为分割符下面举几个例子：Mybatis的级联操作：一般来说只会使用级联查询，其他的如级联删除等维护的成本较大，一般不会使用级联查询—一对多查询（部门和职员之间的一对多的关系 在部门的实体类中声明list类型的数组，里面是职员类型的对象，有两种方式） 级联查询–多对一查询（根据职员的编号查询员工的基本信息和部门的基本信息，员工的实体类型中有一个部门类型的参数） Mybatis分页（PageHelper插件）1.引入pagehelper的依赖 &lt; dependency &gt;&#8194;&#8194;&#8194; &lt; groupId&gt;com.github.pagehelper&lt; /groupId &gt; &#8194;&#8194;&#8194; &lt; artifactId &gt;pagehelper&lt; /artifactId &gt; &#8194;&#8194;&#8194; &lt; version &gt;4.1.6&lt; /version &gt; &lt; /dependency &gt; 2.在Mybatis配置文件中进行配置（plugins应该在environments的上面） &lt; plugin interceptor=”com.github.pagehelper.PageHelper” &gt; &#8194;&#8194;&#8194; &lt; property name=”dialect” value=”mysql”/ &gt; &#8194;&#8194;&#8194; &lt; property name=”offsetAsPageNum” value=”false”/ &gt; &#8194;&#8194;&#8194; &lt; property name=”rowBoundsWithCount” value=”false”/ &gt; &#8194;&#8194;&#8194; &lt; property name=”pageSizeZero” value=”true”/&gt; &#8194;&#8194;&#8194; &lt; property name=”reasonable” value=”false”/ &gt; &#8194;&#8194;&#8194; &lt; property name=”supportMethodsArguments” value=”false”/&gt; &#8194;&#8194;&#8194; &lt; property name=”returnPageInfo” value=”none”/&gt; &lt; /plugin &gt;3.具体使用在查询之前进行分页： PageHelper.startPage(1,10,true); //第一页 每页显示10条想研究源码的：请看http://www.ccblog.cn/92.htm","categories":[],"tags":[{"name":"Mybatis源码分析（三）","slug":"Mybatis源码分析（三）","permalink":"http://yoursite.com/tags/Mybatis源码分析（三）/"}]},{"title":"Mybatis源码分析（二）","slug":"Mybatis源码分析（二）","date":"2018-12-25T12:42:54.000Z","updated":"2018-12-27T02:39:09.197Z","comments":true,"path":"2018/12/25/Mybatis源码分析（二）/","link":"","permalink":"http://yoursite.com/2018/12/25/Mybatis源码分析（二）/","excerpt":"","text":"由于Mybatis和Spring框架中都大量使用了代理模式，所以先讲一下代理模式，据我所知，代理模式一般有两种实现，一种是通过组合的方式来实现代理模式这种实现方式比较简单，可以看看菜鸟教程的代理模式：http://www.runoob.com/design-pattern/proxy-pattern.html， 但是在框架中都不会使用这种方式来实现代理，一般是使用java的反射机制来实现的，比如说Mybatis的封装jdbc的操作就是用jdk的动态代理来实现的代理模式：1.作用：将主要业务和次要业务进行松耦合的处理 2.JDK代理模式实现 1 接口角色： 定义所有需要被监听行为 2.接口实现类：中国人，印度人 3.通知类： 1）次要业务进行具体实现 2）通知JVM,当前被拦截的主要业务方法与次要业务方法应该如何绑定执行 4.监控对象（代理对象） 1） 被监控实例对象 2） 需要被监控监控行为 3）具体通知类实例对象Mybatis中Mapper配置文件详解1.#{}的参数问题 #{}实现的是向prepareStatement中的预处理语句中设置参数值，sql语句中#{}表示一个占位符即 ？ 使用#{参数名},将参数的内容添加到sql语句中指定位置. 如果当前sql语句中只有一个参数,此时参数名称可以随意定义 但是,如果当前sql语句有多个参数,此时参数名称应该是与当前表关联[实体类的属性名]或则[Map集合关键字] 可以采用一下两种方式来对sql语句进行参数的赋值操作 2.#和$的区别其实#就是起一个占位符的作用，就是？，而$符号则是采用直接赋值的方式，简单来说如果使用#{}，会将{}里面的传入的值自动解析成为带引号的值，如果使用$就不会带引号，举个例子在登录的时候有一条查询语句，写了一个错误的用户名，用$符号进行解析的时候就是select from test where username=’张三’ or ‘1’=’1’ and password=’13’;但是用#解析的时候就会加上引号，就可以防止sql注入，大多数情况下我们都会使用#符号的方式来避免sql注入，但是在一些特殊情况就会使用到$符号:比如说现在有两张数据库表，在一条sql语句中要对数据库的表名进行动态的改变，这时候必须用$符号 还有就是说动态的指定查询语句中的排序字段时，必须使用$ select from dept order by ${name}3.Mybatis–Mapper映射文件之resultMap先说一下resultType吧，就是说如果sql映射文件的返回的结果集刚好是我们定义的实体类对象，这个时候就用resultType，但是当实体类的参数和数据库中的字段不一样时，java通过反射机制进行赋值的时候就会出错，这个时候就要运用resultMap把数据库的字段和实体类的参数进行一一对应1）ResultMap中的constructor标签（这个不是很重要，可以选择性忽略）作用：有可能存在一种情况就是说实体类有一个参数是数据库对应表中的字段所没有的，这个时候可以通过构造函数算出这个实体类的参数的值，代码如下 配置文件如下： ###如果说数据库中的字段是tb_name话，Mybatis会把横杠去掉并把后面的第一个字母变为大写，就是tbName再去实体类中进行匹配4.Mybatis动态sqlif：根据if标签里面的条件是否为真来决定标签里面的内容是否可以到sql语句中choose when othenwise —-分支选择条件where： 1.如果where标签内部所有的判断都不成立。在查询语句中是不会出现where或则只出现 where1=1 2.where标签中，将第一个满足条件的语句中前部包含【and ,or】自动取消set:一般用于更新语句中动态指定需要更新字段信息，往往需要与if标签使用，自动将最后一个更新字段后面“，”取消trim:自定义第一个满足条件前部的代替内容也可以自定义最后一个满足条件后面的代替内容","categories":[],"tags":[{"name":"Mybatis源码分析（二）","slug":"Mybatis源码分析（二）","permalink":"http://yoursite.com/tags/Mybatis源码分析（二）/"}]},{"title":"Mybatis源码分析（一）","slug":"Mybatis源码分析（一）","date":"2018-12-25T03:37:49.000Z","updated":"2018-12-29T02:31:28.001Z","comments":true,"path":"2018/12/25/Mybatis源码分析（一）/","link":"","permalink":"http://yoursite.com/2018/12/25/Mybatis源码分析（一）/","excerpt":"","text":"关于具体的框架的搭建就不往上贴了，不会的话看一下这个链接：https://www.cnblogs.com/fangjet/p/7639606.html Mybatis框架源码分析：//读取配置文件InputStream inputstream=Resources.getResourcesAsStream(“mybatis-config.xml”);//创建sqlSessionFactory对象SqlSessionFactory sqlsessionFactory=new SqlSessionFactoryBuilder() .build(inputStream);//创建SqlSession对象session=sqlsessionFactory.openSession();//操作session.insert(“insertStu”,student)//提交session.commit();session.close(); SqlSessionFactory sqlsessionFactory=new SqlSessionFactoryBuilder().build(inputStream);首先把MyBatis的配置文件封装成IO流的方式，再者就是创建sqlsessionFactory的过程，这里面采用了工厂模式来生成sqlsessionFactory的实例，用SqlSessionFactoryBuilder的build方法，build方法里面有一个自己的重载的过程，这是因为在这里可以改变Mybatis配置文件中的properties,environment等信息，真正在build方法里面实现的还是用XMLConfigBuilder的parse（）方法来实现对mybatis配置文件的一个解析，这个parse方法返回的configuration对象就有了配置文件的一些信息，这个configuration对象会作为build方法的一个参数，调用build方法其实就是新建了一个DefaultSqlSessionFactory对象，他是SqlSessionFactory的实现类，也就是说最后返回的就是DefaultSqlSessionFactory对象 session=sqlsessionFactory.openSession();由sqlsessionFactory这个工厂来创造sqlsession对象，返回的还是defaultSqlSession对象，这个对象里面有一些属性，比如dirty，autocommit，executor等一些属性 session.insert(“insertStu”,student) （insertStu是映射文件的id）这个方法里面可以帮我们找到三个问题的答案:1.mybatis是如何把insertStu与映射文件的id对应起来的？2.mybatis如何把数据绑定到sql语句中？3.mybatis如何输送sql语句？insert方法其实调用的是update方法，里面会传入上面的两个参数，当sqlsession对象在执行的时候，他要根据configuration对象的mapper映射的id找到当前执行的sql语句，同时通过对应关系把值赋值到对应的 sql语句中 ，下来就是执行器Executor进行sql语句的执行工作，这里面应该就是封装的一些jdbc的操作，来完成对数据库的交互工作，在这个操作之前，会有MapperStatement对象将赋值内容和sql占位符进行绑定的一个操作。 session.commit();这个里面的主要是通过sqlsession对象里面的dirty属性来决定数据库的事务提交的方式，具体就是当dirty属性为true时，就是当sql语句执行完毕后，事务可以进行提交，当dirty属性为false时，当sql语句执行完毕后，事务可以进行回滚 Mybatis标签解析：mybatis的sql语句的配置文件不能为空，其次就是有一个xml解析器会把配置文件里面的sql语句的参数先全部换为占位符，再把参数名放在一个list集合中，等到使用的时候，使用反射机制把list数组里面的值读取出来做赋值处理 Mybatis标签解析—-TypeHandle 每当Mybatis设置参数到PreparedStatemnet或者从ResultSet 结果集中取得值时，就会使用TypeHandle对象来处理数据库类型与java类型之间的转换，一般来说，类型转换可以满足日常的需求，但我们也可以自定义一个类型转换器，比如说数据库的flag字段是int类型，到Java代码中必须转换为Boolean类型，这是就需要自定义类型转换器 （1）实体类 （2） 表中字段 （3） 开发自定义类型转换器 （4） 在MyBatis核心配置文件注册自定义类型转换器 这样其实是一个全局生效的配置，无关哪个数据库，无关哪张表，主要有这两个字段的，都会走自定义的类型转换器（1） 在Mapper.xml文件中指定使用自定义类型转换器场合 （2） 在查询Statement中指定对应的ResultMap 这个意思就是说只有执行这个select语句的时候，才会发生类型的转换，相当于给定了类型转换的时机 Mybatis标签解析—-ObjectFactory 这个标签的作用就是说，当Mybatis查询完毕后，是要把查询后的ResultSet结果集转换为对应的实体对象的，而ObjectFacory是负责创建这个对象的假如有一种情况就是说实体类中有一个字段country但是数据库的表中没有这个字段这时候可以自定义一个ObjectFactory来实现这个需求，就是重新定义类实例创建的规则（1）自定义ObjectFactory工厂 （2） 在MyBatis核心文件中注册自定义工厂 Mybatis解析—plugins拦截器 拦截器的一个作用就是我们可以拦截某些方法的调用，我们可以选择在这些被拦截的方法执行前后加上某些逻辑，也可以在执行这些被拦截的方法时执行自己的逻辑而不再执行被拦截的方法。Mybatis拦截器设计的一个初衷就是为了供用户在某些时候可以实现自己的逻辑而不必去动Mybatis固有的逻辑。打个比方，对于Executor，Mybatis中有几种实现：BatchExecutor、ReuseExecutor、SimpleExecutor和CachingExecutor。这个时候如果你觉得这几种实现对于Executor接口的query方法都不能满足你的要求，那怎么办呢？是要去改源码吗？当然不。我们可以建立一个Mybatis拦截器用于拦截Executor接口的query方法，在拦截之后实现自己的query方法逻辑，之后可以选择是否继续执行原来的query方法。 对于拦截器Mybatis为我们提供了一个Interceptor接口，通过实现该接口就可以定义我们自己的拦截器。我们先来看一下这个接口的定义： 我们可以看到在该接口中一共定义有三个方法，intercept、plugin和setProperties。plugin方法是拦截器用于封装目标对象的，通过该方法我们可以返回目标对象本身，也可以返回一个它的代理。当返回的是代理的时候我们可以对其中的方法进行拦截来调用intercept方法，当然也可以调用其他方法，这点将在后文讲解。setProperties方法是用于在Mybatis配置文件中指定一些属性的。 定义自己的Interceptor最重要的是要实现plugin方法和intercept方法，在plugin方法中我们可以决定是否要进行拦截进而决定要返回一个什么样的目标对象。而intercept方法就是要进行拦截的时候要执行的方法。 对于plugin方法而言，其实Mybatis已经为我们提供了一个实现。Mybatis中有一个叫做Plugin的类，里面有一个静态方法wrap(Object target,Interceptor interceptor)，通过该方法可以决定要返回的对象是目标对象还是对应的代理。 对于实现自己的Interceptor而言有两个很重要的注解，一个是@Intercepts，其值是一个@Signature数组。@Intercepts用于表明当前的对象是一个Interceptor，而@Signature则表明要拦截的接口、方法以及对应的参数类型。来看一个自定义的简单Interceptor： 然后在MyBatis核心配置文件注册自定义拦截器 MyBatis自定义拦截器，可以拦截接口只有四种.Executor.class， StatementHandler.class（生成一个preparement对象，并把sql语句放到preparement里面）ParameterHandler.class,（参数处理器主要是把传入的参数对象填充到sql映射文件的标签里面）ResultSetHandler.class（当Mybatis进行查询的时候，进行当前数据行里面的值和对象的哪一个参数进行匹配的工作）","categories":[],"tags":[{"name":"Mybatis源码分析（一）","slug":"Mybatis源码分析（一）","permalink":"http://yoursite.com/tags/Mybatis源码分析（一）/"}]},{"title":"Hello World","slug":"hello-world","date":"2018-12-24T01:30:00.616Z","updated":"2018-12-24T01:30:00.617Z","comments":true,"path":"2018/12/24/hello-world/","link":"","permalink":"http://yoursite.com/2018/12/24/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}